{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import tensorflow as tf\n",
    "from logging_future import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"C:/Users/workspace/brad_public_workspace_on_win/SH_tongliang/data/数据库/火币日线/\" \n",
    "file = \"11_14_huobi_btcusdt_copy_for_ML_.csv\"\n",
    "df = pd.read_csv(location + file, engine=\"python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use inner&outer functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lstm_run_through_all(test_train_split, time_step, rnn_unit, batch_size, train_times, lr):\n",
    "    # Use this code to prevent the kernel from requesting to start again everytime we run the model. \n",
    "    tf.reset_default_graph()\n",
    "    \n",
    "    data_len = len(df)\n",
    "    total_days = data_len\n",
    "    test_end = total_days\n",
    "    train_begin = 0\n",
    "    \n",
    "    pre_data = df.iloc[:, 4].values  # 取收盘价计算标签\n",
    "    label = []\n",
    "    for i in range(1, len(pre_data)):\n",
    "        label.append(round(pre_data[i] - pre_data[i - 1], 4))\n",
    "\n",
    "    df.loc[1:, 'label'] = label\n",
    "    df['label'] = df['label'].shift(-1)\n",
    "    df.fillna(method='ffill', inplace = True)\n",
    "    data = df.iloc[:, [1, 2, 3, 5]].values  # 获取特征量及标签，类型为np.ndarray\n",
    "    # logger.info(data[0:5])\n",
    "\n",
    "    \n",
    "    # 参数类别一：\n",
    "    \"\"\"\n",
    "    保持以下参数不变：\n",
    "\n",
    "    利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
    "    time_step = 20\n",
    "    rnn_unit = 10  # 隐藏层单元数量 ##################调整这个\n",
    "    input_size = 3  # 输入个数  \n",
    "    output_size = 1  # 输出个数\n",
    "    batch_size = 80  # 批量大小  #################调整这个\n",
    "    train_times = 20  # 训练次数\n",
    "    lr = 0.001  # 学习率\n",
    "\n",
    "\n",
    "    test_train_split 参数调优:\n",
    "\n",
    "    test_train_split   accuracy       信号强度\n",
    "           0.2           0.55         -55.86\n",
    "           0.3           0.52         -39.31\n",
    "           0.4           0.4928        -9.88\n",
    "           0.5           0.5111       -28.13\n",
    "           0.6           0.5          -13.87\n",
    "           0.7           0.4961       -27.13\n",
    "           0.8           0.4967       -28.58\n",
    "           0.9           0.5          -9.06\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    test_train_split = test_train_split\n",
    "    time_step = time_step # 20 as default\n",
    "    split_batch = int(total_days/time_step) \n",
    "    time_step_multiple = int(test_train_split*split_batch)\n",
    "    test_begin = int(test_end - (time_step)*time_step_multiple)\n",
    "    train_end = test_begin\n",
    "\n",
    "    # 这里 test_end - test_begin的差一定要是time_step的倍数\n",
    "    print (\"split_batch: \", split_batch)\n",
    "    print (\"train_test_split_rate: \", test_train_split)\n",
    "    print (\"train_begin: \", train_begin)\n",
    "    print (\"train_end: \", train_end)\n",
    "    print (\"test_begin: \", test_begin)\n",
    "    print (\"test_end: \", test_end)\n",
    "    print (\"time_step: \", time_step)\n",
    "\n",
    "    # 参数类别二：\n",
    "\n",
    "    rnn_unit = rnn_unit # 1o as default  # 隐藏层单元数量 ##################调整这个\n",
    "    input_size = 3  # 输入个数  \n",
    "    output_size = 1  # 输出个数\n",
    "    batch_size = batch_size # 80 as default  # 批量大小  #################调整这个\n",
    "    train_times = train_times # 20 as default  # 训练次数\n",
    "    lr = lr # 0.001 as default  # 学习率\n",
    "    # 一般调整隐藏层数量、批量大小及学习率这几个超参数\n",
    "    # 输入和输出则由特征量和标签确定\n",
    "    # 本例中，以开盘价、最高价、最低价为特征量，\n",
    "    # 以收盘价差即涨跌作为标签\n",
    "    \n",
    "    \n",
    "    \n",
    "    print (\"=\"*60)\n",
    "    def get_train_data(batch_size, time_step, train_begin, train_end):\n",
    "        batch_index = []\n",
    "        data_train = data[train_begin + 1:train_end]\n",
    "        normalized_train_data = (\n",
    "            data_train - np.mean(data_train, axis=0)) / np.std(\n",
    "                data_train, axis=0)\n",
    "        # logger.info('normalized_train_data.shape: ', normalized_train_data.shape)\n",
    "        # logger.info(len(normalized_train_data))\n",
    "        # logger.info(type(normalized_train_data))\n",
    "        # logger.info(len([0, 2]))\n",
    "        # logger.info(normalized_train_data[0:20])\n",
    "        # logger.info(normalized_train_data[0:20, 1])\n",
    "\n",
    "        train_x, train_y = [], []\n",
    "        for i in range(len(normalized_train_data) - time_step):\n",
    "            if i % batch_size == 0:\n",
    "                batch_index.append(i)\n",
    "\n",
    "            x = normalized_train_data[i:i + time_step, :3]\n",
    "            y = normalized_train_data[i:i + time_step, 3, np.newaxis]\n",
    "            train_x.append(x.tolist())\n",
    "            train_y.append(y.tolist())\n",
    "\n",
    "        batch_index.append(len(normalized_train_data) - time_step)\n",
    "        return batch_index, train_x, train_y\n",
    "\n",
    "\n",
    "    def get_test_data(time_step, test_begin, test_end):\n",
    "        data_test = data[test_begin:test_end]\n",
    "        test_y = data_test[:, 3]\n",
    "        mean = np.mean(data_test, axis=0)\n",
    "        std = np.std(data_test, axis=0)\n",
    "        normalized_test_data = (data_test - mean) / std\n",
    "        size = (len(normalized_test_data) + time_step - 1) // time_step\n",
    "        test_x, test_y = [], []\n",
    "        for i in range(size - 1):\n",
    "            x = normalized_test_data[i * time_step:(i + 1) * time_step, :3]\n",
    "            y = normalized_test_data[i * time_step:(i + 1) * time_step, 3]\n",
    "            test_x.append(x.tolist())\n",
    "            test_y.extend(y)\n",
    "            # print('type(y): ', type(y))\n",
    "\n",
    "        test_x.append((normalized_test_data[(i + 1) * time_step:, :3]).tolist())\n",
    "        test_y.extend((normalized_test_data[(i + 1) * time_step:, 3]).tolist())\n",
    "        return mean, std, test_x, test_y\n",
    "\n",
    "\n",
    "    weights = {\n",
    "        'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "        'out': tf.Variable(tf.random_normal([rnn_unit, 1]))\n",
    "    }\n",
    "    biases = {\n",
    "        'in': tf.Variable(tf.constant(0.1, shape=[\n",
    "            rnn_unit,\n",
    "        ])),\n",
    "        'out': tf.Variable(tf.constant(0.1, shape=[\n",
    "            1,\n",
    "        ]))\n",
    "    }\n",
    "\n",
    "\n",
    "    # 定义神经网络变量\n",
    "    def lstm(X):\n",
    "        batch_size = tf.shape(X)[0]\n",
    "        time_step = tf.shape(X)[1]\n",
    "        w_in = weights['in']\n",
    "        b_in = biases['in']\n",
    "        input_ = tf.reshape(X, [-1, input_size])\n",
    "        # print('input_.shape: ', input_.shape)\n",
    "        input_rnn = tf.matmul(input_, w_in) + b_in\n",
    "        # print('input_rnn.shape: ', input_rnn.shape)\n",
    "        # tensor转换成3维，作为cell的输入\n",
    "        input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit])\n",
    "        # print('input_rnn.shape: ', input_rnn.shape)\n",
    "        cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "        init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "        output_rnn, final_state = tf.nn.dynamic_rnn(\n",
    "            cell, input_rnn, initial_state=init_state, dtype=tf.float32)\n",
    "        output = tf.reshape(output_rnn, [-1, rnn_unit])\n",
    "        w_out = weights['out']\n",
    "        b_out = biases['out']\n",
    "        pred = tf.matmul(output, w_out) + b_out\n",
    "        return pred, final_state\n",
    "\n",
    "\n",
    "    # 训练模型\n",
    "    def train_lstm(batch_size, time_step, train_begin, train_end):\n",
    "        X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "        Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "        batch_index, train_x, train_y = get_train_data(batch_size, time_step,\n",
    "                                                       train_begin, train_end)\n",
    "        with tf.variable_scope('future_lstm'):\n",
    "            pred, _ = lstm(X)\n",
    "            loss = tf.reduce_mean(\n",
    "                tf.square(tf.reshape(pred, [-1]) - tf.reshape(Y, [-1])))\n",
    "            train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "            saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "\n",
    "            with tf.Session() as sess:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "                for i in range(train_times):\n",
    "                    for step in range(len(batch_index) - 1):\n",
    "                        _, loss_ = sess.run(\n",
    "                            [train_operation, loss],\n",
    "                            feed_dict={\n",
    "                                X:\n",
    "                                train_x[batch_index[step]:batch_index[step + 1]],\n",
    "                                Y: train_y[batch_index[step]:batch_index[step + 1]]\n",
    "                            })\n",
    "                    # print('Number of iterations: {} , loss: {}'.format(i, loss_))\n",
    "#                     logger.info('Number of iterations: {} , loss: {}'.format(\n",
    "#                         i, loss_))\n",
    "    #             print('model saved: ', saver.save(sess, 'model_save1/model.ckpt'))\n",
    "                print('The train has finished')\n",
    "\n",
    "\n",
    "    train_lstm(batch_size, time_step, train_begin, train_end)\n",
    "\n",
    "\n",
    "    def prediction(time_step):\n",
    "        X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    #     print (\"X: \", X)  #brad's peek\n",
    "        mean, std, test_x, test_y = get_test_data(time_step, test_begin, test_end)\n",
    "        with tf.variable_scope('future_lstm', reuse=True):\n",
    "            pred, _ = lstm(X)\n",
    "            saver = tf.train.Saver(tf.global_variables())\n",
    "            with tf.Session() as sess:\n",
    "                model_file = tf.train.latest_checkpoint('model_save1')\n",
    "                saver.restore(sess, model_file)\n",
    "                test_predict = []\n",
    "                # brad's peek:\n",
    "    #             print(\"test_x\")\n",
    "    #             print (test_x)\n",
    "                for step in range(len(test_x)):\n",
    "                    # 一次出time_step个结果，results.shape: (20, 1)\n",
    "                    results = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "                    # predict = tf.reshape(results, [-1])\n",
    "                    predict = results.reshape(-1)\n",
    "                    test_predict.extend(predict)\n",
    "                # brad's peek:\n",
    "    #             print (test_predict)\n",
    "                # 还原真实值\n",
    "                # brad's peek:\n",
    "    #             print (\"test_y\",test_y)\n",
    "                test_y = np.array(test_y) * std[3] + mean[3]\n",
    "                test_predict = np.array(test_predict) * std[3] + mean[3]\n",
    "                true_y = test_y\n",
    "\n",
    "\n",
    "                # print('test_predict.shape: ', test_predict.shape)\n",
    "                # print('true_y.shape: ', true_y.shape)\n",
    "                out = np.c_[test_predict, true_y]\n",
    "                out_csv = pd.DataFrame(\n",
    "                    data=out, index=None, columns=['prediction', 'true'])\n",
    "#                 out_csv.to_csv('pred_and_true_20180623.csv')\n",
    "                # 计算精度\n",
    "                right, wrong = 0, 0\n",
    "                calc_data = map(lambda x, y: tuple((x, y)), test_predict,\n",
    "                                test_y[:len(test_predict)])\n",
    "                for data in calc_data:\n",
    "                    if data[0] * data[1] > 0 or data[0] == data[1]:\n",
    "                        right += 1\n",
    "                    else:\n",
    "                        wrong += 1\n",
    "                accuracy = right / (right + wrong)\n",
    "                print(\"利用过去一天: \"+str(df[:test_end].iloc[-1, :].values[0]) + \", 来预测下一天：\")\n",
    "                print (out_csv.iloc[-1, 0])\n",
    "                logger.info('The accuracy of this prediction: ')\n",
    "                logger.info(accuracy)\n",
    "                # print('The accuracy of this prediction: ', accuracy)\n",
    "                # 计算偏差程度\n",
    "                # deviation = np.average(\n",
    "                #     np.abs(test_predict - test_y[:len(test_predict)]) /\n",
    "                #     test_y[:len(test_predict)])\n",
    "                # print('The deviation of this prediction: ', deviation)\n",
    "                # logger.info('The deviation of this prediction: ')\n",
    "                # logger.info(deviation)\n",
    "                # logger.info(np.abs(test_predict - test_y[:len(test_predict)]))\n",
    "                # logger.info(test_y[:len(test_predict)])\n",
    "\n",
    "    #             fig = plt.figure()\n",
    "    #             fig.set_size_inches(64, 48)\n",
    "    #             ax = plt.gca()\n",
    "    #             ax.spines['left'].set_linewidth(3)\n",
    "    #             ax.spines['bottom'].set_linewidth(3)\n",
    "    #             # 设置刻度大小\n",
    "    #             rc('xtick', labelsize=40)\n",
    "    #             rc('ytick', labelsize=40)\n",
    "    #             plt.plot(\n",
    "    #                 list(range(len(test_predict))),\n",
    "    #                 test_predict,\n",
    "    #                 color='blue',\n",
    "    #                 label='predict',\n",
    "    #             )\n",
    "    #             plt.plot(\n",
    "    #                 list(range(len(test_y))), test_y, color='red', label='real')\n",
    "    #             # 设置图例及X、Y轴标签，label名称支持Tex语法\n",
    "    #             plt.legend(loc='best', fontsize=60)\n",
    "    #             plt.xlabel(r'$\\rm{dailydata}$', fontdict={'size': 60})\n",
    "    #             plt.ylabel(r'$\\rm{fluctuation}$', fontdict={'size': 60})\n",
    "    #             plt.savefig(\n",
    "    #                 'future_lstm_train{}_accuracy{:.4f}.png'.format(\n",
    "    #                     train_times, accuracy),\n",
    "    #                 dpi=300)\n",
    "    #             plt.show()\n",
    "\n",
    "    prediction(time_step)\n",
    "    print (\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-28.125072479248047\n",
      "2018-11-18 19:30:33,907 INFO in line 171: The accuracy of this prediction: \n",
      "2018-11-18 19:30:33,910 INFO in line 172: 0.5111111111111111\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "lstm_run_through_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 先测试一个变量的参数：test_train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split_batch:  19\n",
      "train_test_split_rate:  0.2\n",
      "train_begin:  0\n",
      "train_end:  327\n",
      "test_begin:  327\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-56.92164993286133\n",
      "2018-11-18 19:47:47,695 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:47,705 INFO in line 250: 0.48333333333333334\n",
      "============================================================\n",
      "split_batch:  19\n",
      "train_test_split_rate:  0.3\n",
      "train_begin:  0\n",
      "train_end:  287\n",
      "test_begin:  287\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-38.843162536621094\n",
      "2018-11-18 19:47:49,865 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:49,865 INFO in line 250: 0.43\n",
      "============================================================\n",
      "split_batch:  19\n",
      "train_test_split_rate:  0.4\n",
      "train_begin:  0\n",
      "train_end:  247\n",
      "test_begin:  247\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-12.930143356323242\n",
      "2018-11-18 19:47:51,876 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:51,879 INFO in line 250: 0.4642857142857143\n",
      "============================================================\n",
      "split_batch:  19\n",
      "train_test_split_rate:  0.5\n",
      "train_begin:  0\n",
      "train_end:  207\n",
      "test_begin:  207\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-28.065738677978516\n",
      "2018-11-18 19:47:53,738 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:53,748 INFO in line 250: 0.4888888888888889\n",
      "============================================================\n",
      "split_batch:  19\n",
      "train_test_split_rate:  0.6\n",
      "train_begin:  0\n",
      "train_end:  167\n",
      "test_begin:  167\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-14.265297889709473\n",
      "2018-11-18 19:47:55,551 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:55,551 INFO in line 250: 0.4636363636363636\n",
      "============================================================\n",
      "split_batch:  19\n",
      "train_test_split_rate:  0.7\n",
      "train_begin:  0\n",
      "train_end:  127\n",
      "test_begin:  127\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-27.607318878173828\n",
      "2018-11-18 19:47:57,321 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:57,331 INFO in line 250: 0.5038461538461538\n",
      "============================================================\n",
      "split_batch:  19\n",
      "train_test_split_rate:  0.8\n",
      "train_begin:  0\n",
      "train_end:  87\n",
      "test_begin:  87\n",
      "test_end:  387\n",
      "time_step:  20\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
      "-25.100696563720703\n",
      "2018-11-18 19:47:58,909 INFO in line 249: The accuracy of this prediction: \n",
      "2018-11-18 19:47:58,909 INFO in line 250: 0.5033333333333333\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "test_train_split_var_list = [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "\n",
    "for para in test_train_split_var_list:\n",
    "    test_train_split = para\n",
    "    lstm_run_through_all(test_train_split, time_step = 20, \n",
    "                                           rnn_unit = 10, \n",
    "                                           batch_size = 80, \n",
    "                                           train_times = 20, \n",
    "                                           lr = 0.001)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
