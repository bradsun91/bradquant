{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import tensorflow as tf\n",
    "from logging_future import logger\n",
    "\n",
    "location = \"C:/Users/workspace/brad_public_workspace_on_win/SH_tongliang/data/数据库/火币日线/\" \n",
    "file = \"11_14_huobi_btcusdt_copy_for_ML.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn_unit = 10  # 隐藏层单元数量 ##################调整这个\n",
    "# input_size = 3  # 输入个数  \n",
    "# output_size = 1  # 输出个数\n",
    "# batch_size = 80  # 批量大小  #################调整这个\n",
    "# time_step = 20  # 时间步   \n",
    "# lr = 0.001  # 学习率\n",
    "# # 一般调整隐藏层数量、批量大小及学习率这几个超参数\n",
    "# # 输入和输出则由特征量和标签确定\n",
    "# # 本例中，以开盘价、最高价、最低价为特征量，\n",
    "# # 以收盘价差即涨跌作为标签\n",
    "\n",
    "# df = pd.read_csv(location + file, engine=\"python\")\n",
    "# pre_data = df.iloc[:, 4].values  # 取收盘价计算标签\n",
    "# label = []\n",
    "# for i in range(1, len(pre_data)):\n",
    "#     label.append(round(pre_data[i] - pre_data[i - 1], 4))\n",
    "\n",
    "# df.loc[1:, 'label'] = label\n",
    "# data = df.iloc[:, [1, 2, 3, 5]].values  # 获取特征量及标签，类型为np.ndarray\n",
    "# # logger.info(data[0:5])\n",
    "\n",
    "# train_begin = 0\n",
    "# train_end = 200\n",
    "# train_times = 10  # 训练次数\n",
    "# test_begin = 200\n",
    "# test_end = 380"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 1 get_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_train_data(batch_size, time_step, train_begin, train_end):\n",
    "#     batch_index = []\n",
    "#     data_train = data[train_begin + 1:train_end]\n",
    "#     normalized_train_data = (\n",
    "#         data_train - np.mean(data_train, axis=0)) / np.std(\n",
    "#             data_train, axis=0)\n",
    "#     # logger.info('normalized_train_data.shape: ', normalized_train_data.shape)\n",
    "#     # logger.info(len(normalized_train_data))\n",
    "#     # logger.info(type(normalized_train_data))\n",
    "#     # logger.info(len([0, 2]))\n",
    "#     # logger.info(normalized_train_data[0:20])\n",
    "#     # logger.info(normalized_train_data[0:20, 1])\n",
    "\n",
    "#     train_x, train_y = [], []\n",
    "#     for i in range(len(normalized_train_data) - time_step):\n",
    "#         if i % batch_size == 0:\n",
    "#             batch_index.append(i)\n",
    "\n",
    "#         x = normalized_train_data[i:i + time_step, :3]\n",
    "#         y = normalized_train_data[i:i + time_step, 3, np.newaxis]\n",
    "#         train_x.append(x.tolist())\n",
    "#         train_y.append(y.tolist())\n",
    "\n",
    "#     batch_index.append(len(normalized_train_data) - time_step)\n",
    "#     return batch_index, train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_index = []\n",
    "# data_train = data[train_begin + 1:train_end]\n",
    "# normalized_train_data = (\n",
    "#     data_train - np.mean(data_train, axis=0)) / np.std(\n",
    "#         data_train, axis=0)\n",
    "# # logger.info('normalized_train_data.shape: ', normalized_train_data.shape)\n",
    "# # logger.info(len(normalized_train_data))\n",
    "# # logger.info(type(normalized_train_data))\n",
    "# # logger.info(len([0, 2]))\n",
    "# # logger.info(normalized_train_data[0:20])\n",
    "# # logger.info(normalized_train_data[0:20, 1])\n",
    "\n",
    "# train_x, train_y = [], []\n",
    "# for i in range(len(normalized_train_data) - time_step):\n",
    "#     if i % batch_size == 0:\n",
    "#         batch_index.append(i)\n",
    "\n",
    "#     x = normalized_train_data[i:i + time_step, :3]\n",
    "#     y = normalized_train_data[i:i + time_step, 3, np.newaxis]\n",
    "#     train_x.append(x.tolist())\n",
    "#     train_y.append(y.tolist())\n",
    "\n",
    "# batch_index.append(len(normalized_train_data) - time_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func 2 get_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_test_data(time_step, test_begin, test_end):\n",
    "#     data_test = data[test_begin:test_end]\n",
    "#     test_y = data_test[:, 3]\n",
    "#     mean = np.mean(data_test, axis=0)\n",
    "#     std = np.std(data_test, axis=0)\n",
    "#     normalized_test_data = (data_test - mean) / std\n",
    "#     size = (len(normalized_test_data) + time_step - 1) // time_step\n",
    "#     test_x, test_y = [], []\n",
    "#     for i in range(size - 1):\n",
    "#         x = normalized_test_data[i * time_step:(i + 1) * time_step, :3]\n",
    "#         y = normalized_test_data[i * time_step:(i + 1) * time_step, 3]\n",
    "#         test_x.append(x.tolist())\n",
    "#         test_y.extend(y)\n",
    "#         # print('type(y): ', type(y))\n",
    "\n",
    "#     test_x.append((normalized_test_data[(i + 1) * time_step:, :3]).tolist())\n",
    "#     test_y.extend((normalized_test_data[(i + 1) * time_step:, 3]).tolist())\n",
    "#     return mean, std, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test = data[test_begin:test_end]\n",
    "# test_y = data_test[:, 3]\n",
    "# mean = np.mean(data_test, axis=0)\n",
    "# std = np.std(data_test, axis=0)\n",
    "# normalized_test_data = (data_test - mean) / std\n",
    "# size = (len(normalized_test_data) + time_step - 1) // time_step\n",
    "# test_x, test_y = [], []\n",
    "# for i in range(size - 1):\n",
    "#     x = normalized_test_data[i * time_step:(i + 1) * time_step, :3]\n",
    "#     y = normalized_test_data[i * time_step:(i + 1) * time_step, 3]\n",
    "#     test_x.append(x.tolist())\n",
    "#     test_y.extend(y)\n",
    "#     # print('type(y): ', type(y))\n",
    "\n",
    "# test_x.append((normalized_test_data[(i + 1) * time_step:, :3]).tolist())\n",
    "# test_y.extend((normalized_test_data[(i + 1) * time_step:, 3]).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = {\n",
    "#     'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "#     'out': tf.Variable(tf.random_normal([rnn_unit, 1]))\n",
    "# }\n",
    "# biases = {\n",
    "#     'in': tf.Variable(tf.constant(0.1, shape=[\n",
    "#         rnn_unit,\n",
    "#     ])),\n",
    "#     'out': tf.Variable(tf.constant(0.1, shape=[\n",
    "#         1,\n",
    "#     ]))\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 定义神经网络变量\n",
    "# def lstm(X):\n",
    "#     batch_size = tf.shape(X)[0]\n",
    "#     time_step = tf.shape(X)[1]\n",
    "#     w_in = weights['in']\n",
    "#     b_in = biases['in']\n",
    "#     input_ = tf.reshape(X, [-1, input_size])\n",
    "#     # print('input_.shape: ', input_.shape)\n",
    "#     input_rnn = tf.matmul(input_, w_in) + b_in\n",
    "#     # print('input_rnn.shape: ', input_rnn.shape)\n",
    "#     # tensor转换成3维，作为cell的输入\n",
    "#     input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit])\n",
    "#     # print('input_rnn.shape: ', input_rnn.shape)\n",
    "#     cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "#     init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "#     output_rnn, final_state = tf.nn.dynamic_rnn(\n",
    "#         cell, input_rnn, initial_state=init_state, dtype=tf.float32)\n",
    "#     output = tf.reshape(output_rnn, [-1, rnn_unit])\n",
    "#     w_out = weights['out']\n",
    "#     b_out = biases['out']\n",
    "#     pred = tf.matmul(output, w_out) + b_out\n",
    "#     return pred, final_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This part of code is from prediction(timestamp)\n",
    "# X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "# mean, std, test_x, test_y = get_test_data(time_step, test_begin, test_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = tf.shape(X)[0]\n",
    "# time_step = tf.shape(X)[1]\n",
    "# w_in = weights['in']\n",
    "# b_in = biases['in']\n",
    "# input_ = tf.reshape(X, [-1, input_size])\n",
    "# # print('input_.shape: ', input_.shape)\n",
    "# input_rnn = tf.matmul(input_, w_in) + b_in\n",
    "# # print('input_rnn.shape: ', input_rnn.shape)\n",
    "# # tensor转换成3维，作为cell的输入\n",
    "# input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit])\n",
    "# # print('input_rnn.shape: ', input_rnn.shape)\n",
    "# cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "# init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "# output_rnn, final_state = tf.nn.dynamic_rnn(\n",
    "#     cell, input_rnn, initial_state=init_state, dtype=tf.float32)\n",
    "# output = tf.reshape(output_rnn, [-1, rnn_unit])\n",
    "# w_out = weights['out']\n",
    "# b_out = biases['out']\n",
    "# pred = tf.matmul(output, w_out) + b_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func train_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 训练模型\n",
    "# def train_lstm(batch_size, time_step, train_begin, train_end):\n",
    "#     X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "#     Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "#     batch_index, train_x, train_y = get_train_data(batch_size, time_step,\n",
    "#                                                    train_begin, train_end)\n",
    "#     with tf.variable_scope('future_lstm'):\n",
    "#         pred, _ = lstm(X)\n",
    "#         loss = tf.reduce_mean(\n",
    "#             tf.square(tf.reshape(pred, [-1]) - tf.reshape(Y, [-1])))\n",
    "#         train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "#         saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "\n",
    "#         with tf.Session() as sess:\n",
    "#             sess.run(tf.global_variables_initializer())\n",
    "#             for i in range(train_times):\n",
    "#                 for step in range(len(batch_index) - 1):\n",
    "#                     _, loss_ = sess.run(\n",
    "#                         [train_operation, loss],\n",
    "#                         feed_dict={\n",
    "#                             X:\n",
    "#                             train_x[batch_index[step]:batch_index[step + 1]],\n",
    "#                             Y: train_y[batch_index[step]:batch_index[step + 1]]\n",
    "#                         })\n",
    "#                 # print('Number of iterations: {} , loss: {}'.format(i, loss_))\n",
    "#                 logger.info('Number of iterations: {} , loss: {}'.format(\n",
    "#                     i, loss_))\n",
    "#             print('model saved: ', saver.save(sess, 'model_save1/model.ckpt'))\n",
    "#             print('The train has finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "# Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "# batch_index, train_x, train_y = get_train_data(batch_size, time_step,\n",
    "#                                                train_begin, train_end)\n",
    "# with tf.variable_scope('future_lstm'):\n",
    "#     pred, _ = lstm(X)\n",
    "#     loss = tf.reduce_mean(\n",
    "#         tf.square(tf.reshape(pred, [-1]) - tf.reshape(Y, [-1])))\n",
    "#     train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "#     saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "\n",
    "#     with tf.Session() as sess:\n",
    "#         sess.run(tf.global_variables_initializer())\n",
    "#         for i in range(train_times):\n",
    "#             for step in range(len(batch_index) - 1):\n",
    "#                 _, loss_ = sess.run(\n",
    "#                     [train_operation, loss],\n",
    "#                     feed_dict={\n",
    "#                         X:\n",
    "#                         train_x[batch_index[step]:batch_index[step + 1]],\n",
    "#                         Y: train_y[batch_index[step]:batch_index[step + 1]]\n",
    "#                     })\n",
    "#             # print('Number of iterations: {} , loss: {}'.format(i, loss_))\n",
    "#             logger.info('Number of iterations: {} , loss: {}'.format(\n",
    "#                 i, loss_))\n",
    "#         print('model saved: ', saver.save(sess, 'model_save1/model.ckpt'))\n",
    "#         print('The train has finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Func prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prediction(time_step):\n",
    "#     X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "#     mean, std, test_x, test_y = get_test_data(time_step, test_begin, test_end)\n",
    "#     with tf.variable_scope('future_lstm', reuse=True):\n",
    "#         pred, _ = lstm(X)\n",
    "#         saver = tf.train.Saver(tf.global_variables())\n",
    "#         with tf.Session() as sess:\n",
    "#             model_file = tf.train.latest_checkpoint('model_save1')\n",
    "#             saver.restore(sess, model_file)\n",
    "#             test_predict = []\n",
    "#             for step in range(len(test_x)):\n",
    "#                 # 一次出time_step个结果，results.shape: (20, 1)\n",
    "#                 results = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "#                 # predict = tf.reshape(results, [-1])\n",
    "#                 predict = results.reshape(-1)\n",
    "#                 test_predict.extend(predict)\n",
    "\n",
    "#             # 还原真实值\n",
    "#             test_y = np.array(test_y) * std[3] + mean[3]\n",
    "#             test_predict = np.array(test_predict) * std[3] + mean[3]\n",
    "#             true_y = test_y\n",
    "#             # print('test_predict.shape: ', test_predict.shape)\n",
    "#             # print('true_y.shape: ', true_y.shape)\n",
    "#             out = np.c_[test_predict, true_y]\n",
    "#             out_csv = pd.DataFrame(\n",
    "#                 data=out, index=None, columns=['prediction', 'true'])\n",
    "#             out_csv.to_csv('pred_and_true_20180623.csv')\n",
    "#             # 计算精度\n",
    "#             right, wrong = 0, 0\n",
    "#             calc_data = map(lambda x, y: tuple((x, y)), test_predict,\n",
    "#                             test_y[:len(test_predict)])\n",
    "#             for data in calc_data:\n",
    "#                 if data[0] * data[1] > 0 or data[0] == data[1]:\n",
    "#                     right += 1\n",
    "#                 else:\n",
    "#                     wrong += 1\n",
    "#             accuracy = right / (right + wrong)\n",
    "            \n",
    "#             logger.info('The accuracy of this prediction: ')\n",
    "#             logger.info(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with tf.variable_scope('future_lstm', reuse=True):\n",
    "#     pred, _ = lstm(X)\n",
    "#     saver = tf.train.Saver(tf.global_variables())\n",
    "#     with tf.Session() as sess:\n",
    "#         model_file = tf.train.latest_checkpoint('model_save1')\n",
    "#         saver.restore(sess, model_file)\n",
    "#         test_predict = []\n",
    "#         for step in range(len(test_x)):\n",
    "#             # 一次出time_step个结果，results.shape: (20, 1)\n",
    "#             results = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "#             # predict = tf.reshape(results, [-1])\n",
    "#             predict = results.reshape(-1)\n",
    "#             test_predict.extend(predict)\n",
    "\n",
    "#         # 还原真实值\n",
    "#         test_y = np.array(test_y) * std[3] + mean[3]\n",
    "#         test_predict = np.array(test_predict) * std[3] + mean[3]\n",
    "#         true_y = test_y\n",
    "#         # print('test_predict.shape: ', test_predict.shape)\n",
    "#         # print('true_y.shape: ', true_y.shape)\n",
    "#         out = np.c_[test_predict, true_y]\n",
    "#         out_csv = pd.DataFrame(\n",
    "#             data=out, index=None, columns=['prediction', 'true'])\n",
    "#         out_csv.to_csv('pred_and_true_20180623.csv')\n",
    "#         # 计算精度\n",
    "#         right, wrong = 0, 0\n",
    "#         calc_data = map(lambda x, y: tuple((x, y)), test_predict,\n",
    "#                         test_y[:len(test_predict)])\n",
    "#         for data in calc_data:\n",
    "#             if data[0] * data[1] > 0 or data[0] == data[1]:\n",
    "#                 right += 1\n",
    "#             else:\n",
    "#                 wrong += 1\n",
    "#         accuracy = right / (right + wrong)\n",
    "\n",
    "#         logger.info('The accuracy of this prediction: ')\n",
    "#         logger.info(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use this below to explore the values inside"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Use the data on: \"+df[:test_end].iloc[-1, :].values[0] + \", to predict next day's signal\"\n",
    "# df[:test_end].iloc[-1, 0]\n",
    "# df[:test_end].iloc[-1, :].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-16 14:13:43,903 INFO in line 141: Number of iterations: 0 , loss: 0.1809946894645691\n",
      "2018-11-16 14:13:45,910 INFO in line 141: Number of iterations: 1 , loss: 0.18558649718761444\n",
      "2018-11-16 14:13:47,945 INFO in line 141: Number of iterations: 2 , loss: 0.19242043793201447\n",
      "2018-11-16 14:13:49,851 INFO in line 141: Number of iterations: 3 , loss: 0.1982775181531906\n",
      "2018-11-16 14:13:51,739 INFO in line 141: Number of iterations: 4 , loss: 0.19590194523334503\n",
      "2018-11-16 14:13:53,637 INFO in line 141: Number of iterations: 5 , loss: 0.19072841107845306\n",
      "2018-11-16 14:13:55,762 INFO in line 141: Number of iterations: 6 , loss: 0.2379152923822403\n",
      "2018-11-16 14:13:57,706 INFO in line 141: Number of iterations: 7 , loss: 0.19507364928722382\n",
      "2018-11-16 14:13:59,718 INFO in line 141: Number of iterations: 8 , loss: 0.200111985206604\n",
      "2018-11-16 14:14:01,671 INFO in line 141: Number of iterations: 9 , loss: 0.1972198337316513\n",
      "The train has finished\n",
      "X:  Tensor(\"Placeholder_2:0\", shape=(?, 50, 3), dtype=float32)\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape (1, 34, 3) for Tensor 'Placeholder_2:0', which has shape '(?, 50, 3)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8401c96996f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 237\u001b[1;33m \u001b[0mprediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-8401c96996f7>\u001b[0m in \u001b[0;36mprediction\u001b[1;34m(time_step)\u001b[0m\n\u001b[0;32m    163\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                 \u001b[1;31m# 一次出time_step个结果，results.shape: (20, 1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                 \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m                 \u001b[1;31m# predict = tf.reshape(results, [-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1109\u001b[0m                              \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1110\u001b[0m                              (np_val.shape, subfeed_t.name,\n\u001b[1;32m-> 1111\u001b[1;33m                               str(subfeed_t.get_shape())))\n\u001b[0m\u001b[0;32m   1112\u001b[0m           \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_feedable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Tensor %s may not be fed.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0msubfeed_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape (1, 34, 3) for Tensor 'Placeholder_2:0', which has shape '(?, 50, 3)'"
     ]
    }
   ],
   "source": [
    "rnn_unit = 10  # 隐藏层单元数量 ##################调整这个\n",
    "input_size = 3  # 输入个数  \n",
    "output_size = 1  # 输出个数\n",
    "batch_size = 1  # 批量大小  #################调整这个\n",
    "time_step = 50  # 时间步   \n",
    "lr = 0.001  # 学习率\n",
    "# 一般调整隐藏层数量、批量大小及学习率这几个超参数\n",
    "# 输入和输出则由特征量和标签确定\n",
    "# 本例中，以开盘价、最高价、最低价为特征量，\n",
    "# 以收盘价差即涨跌作为标签\n",
    "\n",
    "df = pd.read_csv(location + file, engine=\"python\")\n",
    "pre_data = df.iloc[:, 4].values  # 取收盘价计算标签\n",
    "label = []\n",
    "for i in range(1, len(pre_data)):\n",
    "    label.append(round(pre_data[i] - pre_data[i - 1], 4))\n",
    "\n",
    "df.loc[1:, 'label'] = label\n",
    "df['label'] = df['label'].shift(-1)\n",
    "data = df.iloc[:, [1, 2, 3, 5]].values  # 获取特征量及标签，类型为np.ndarray\n",
    "# logger.info(data[0:5])\n",
    "\n",
    "train_begin = 0\n",
    "train_end = 200\n",
    "train_times = 10  # 训练次数\n",
    "test_begin = 200\n",
    "test_end = 384\n",
    "\n",
    "\n",
    "def get_train_data(batch_size, time_step, train_begin, train_end):\n",
    "    batch_index = []\n",
    "    data_train = data[train_begin + 1:train_end]\n",
    "    normalized_train_data = (\n",
    "        data_train - np.mean(data_train, axis=0)) / np.std(\n",
    "            data_train, axis=0)\n",
    "    # logger.info('normalized_train_data.shape: ', normalized_train_data.shape)\n",
    "    # logger.info(len(normalized_train_data))\n",
    "    # logger.info(type(normalized_train_data))\n",
    "    # logger.info(len([0, 2]))\n",
    "    # logger.info(normalized_train_data[0:20])\n",
    "    # logger.info(normalized_train_data[0:20, 1])\n",
    "\n",
    "    train_x, train_y = [], []\n",
    "    for i in range(len(normalized_train_data) - time_step):\n",
    "        if i % batch_size == 0:\n",
    "            batch_index.append(i)\n",
    "\n",
    "        x = normalized_train_data[i:i + time_step, :3]\n",
    "        y = normalized_train_data[i:i + time_step, 3, np.newaxis]\n",
    "        train_x.append(x.tolist())\n",
    "        train_y.append(y.tolist())\n",
    "\n",
    "    batch_index.append(len(normalized_train_data) - time_step)\n",
    "    return batch_index, train_x, train_y\n",
    "\n",
    "\n",
    "def get_test_data(time_step, test_begin, test_end):\n",
    "    data_test = data[test_begin:test_end]\n",
    "    test_y = data_test[:, 3]\n",
    "    mean = np.mean(data_test, axis=0)\n",
    "    std = np.std(data_test, axis=0)\n",
    "    normalized_test_data = (data_test - mean) / std\n",
    "    size = (len(normalized_test_data) + time_step - 1) // time_step\n",
    "    test_x, test_y = [], []\n",
    "    for i in range(size - 1):\n",
    "        x = normalized_test_data[i * time_step:(i + 1) * time_step, :3]\n",
    "        y = normalized_test_data[i * time_step:(i + 1) * time_step, 3]\n",
    "        test_x.append(x.tolist())\n",
    "        test_y.extend(y)\n",
    "        # print('type(y): ', type(y))\n",
    "\n",
    "    test_x.append((normalized_test_data[(i + 1) * time_step:, :3]).tolist())\n",
    "    test_y.extend((normalized_test_data[(i + 1) * time_step:, 3]).tolist())\n",
    "    return mean, std, test_x, test_y\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "    'out': tf.Variable(tf.random_normal([rnn_unit, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[\n",
    "        rnn_unit,\n",
    "    ])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[\n",
    "        1,\n",
    "    ]))\n",
    "}\n",
    "\n",
    "\n",
    "# 定义神经网络变量\n",
    "def lstm(X):\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    time_step = tf.shape(X)[1]\n",
    "    w_in = weights['in']\n",
    "    b_in = biases['in']\n",
    "    input_ = tf.reshape(X, [-1, input_size])\n",
    "    # print('input_.shape: ', input_.shape)\n",
    "    input_rnn = tf.matmul(input_, w_in) + b_in\n",
    "    # print('input_rnn.shape: ', input_rnn.shape)\n",
    "    # tensor转换成3维，作为cell的输入\n",
    "    input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit])\n",
    "    # print('input_rnn.shape: ', input_rnn.shape)\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    output_rnn, final_state = tf.nn.dynamic_rnn(\n",
    "        cell, input_rnn, initial_state=init_state, dtype=tf.float32)\n",
    "    output = tf.reshape(output_rnn, [-1, rnn_unit])\n",
    "    w_out = weights['out']\n",
    "    b_out = biases['out']\n",
    "    pred = tf.matmul(output, w_out) + b_out\n",
    "    return pred, final_state\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train_lstm(batch_size, time_step, train_begin, train_end):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "    batch_index, train_x, train_y = get_train_data(batch_size, time_step,\n",
    "                                                   train_begin, train_end)\n",
    "    with tf.variable_scope('future_lstm'):\n",
    "        pred, _ = lstm(X)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.square(tf.reshape(pred, [-1]) - tf.reshape(Y, [-1])))\n",
    "        train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(train_times):\n",
    "                for step in range(len(batch_index) - 1):\n",
    "                    _, loss_ = sess.run(\n",
    "                        [train_operation, loss],\n",
    "                        feed_dict={\n",
    "                            X:\n",
    "                            train_x[batch_index[step]:batch_index[step + 1]],\n",
    "                            Y: train_y[batch_index[step]:batch_index[step + 1]]\n",
    "                        })\n",
    "                # print('Number of iterations: {} , loss: {}'.format(i, loss_))\n",
    "                logger.info('Number of iterations: {} , loss: {}'.format(\n",
    "                    i, loss_))\n",
    "#             print('model saved: ', saver.save(sess, 'model_save1/model.ckpt'))\n",
    "            print('The train has finished')\n",
    "\n",
    "\n",
    "train_lstm(batch_size, time_step, train_begin, train_end)\n",
    "\n",
    "\n",
    "def prediction(time_step):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    print (\"X: \", X)  #brad's peek\n",
    "    mean, std, test_x, test_y = get_test_data(time_step, test_begin, test_end)\n",
    "    with tf.variable_scope('future_lstm', reuse=True):\n",
    "        pred, _ = lstm(X)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        with tf.Session() as sess:\n",
    "            model_file = tf.train.latest_checkpoint('model_save1')\n",
    "            saver.restore(sess, model_file)\n",
    "            test_predict = []\n",
    "            # brad's peek:\n",
    "#             print(\"test_x\")\n",
    "#             print (test_x)\n",
    "            for step in range(len(test_x)):\n",
    "                # 一次出time_step个结果，results.shape: (20, 1)\n",
    "                results = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "                # predict = tf.reshape(results, [-1])\n",
    "                predict = results.reshape(-1)\n",
    "                test_predict.extend(predict)\n",
    "            # brad's peek:\n",
    "#             print (test_predict)\n",
    "            # 还原真实值\n",
    "            # brad's peek:\n",
    "#             print (\"test_y\",test_y)\n",
    "            test_y = np.array(test_y) * std[3] + mean[3]\n",
    "            test_predict = np.array(test_predict) * std[3] + mean[3]\n",
    "            true_y = test_y\n",
    "            \n",
    "            \n",
    "            # print('test_predict.shape: ', test_predict.shape)\n",
    "            # print('true_y.shape: ', true_y.shape)\n",
    "            out = np.c_[test_predict, true_y]\n",
    "            out_csv = pd.DataFrame(\n",
    "                data=out, index=None, columns=['prediction', 'true'])\n",
    "            out_csv.to_csv('pred_and_true_20180623.csv')\n",
    "            # 计算精度\n",
    "            right, wrong = 0, 0\n",
    "            calc_data = map(lambda x, y: tuple((x, y)), test_predict,\n",
    "                            test_y[:len(test_predict)])\n",
    "            for data in calc_data:\n",
    "                if data[0] * data[1] > 0 or data[0] == data[1]:\n",
    "                    right += 1\n",
    "                else:\n",
    "                    wrong += 1\n",
    "            accuracy = right / (right + wrong)\n",
    "            print(\"利用过去一天: \"+df[:test_end].iloc[-1, :].values[0] + \", 来预测下一天：\")\n",
    "            print (out_csv.iloc[-1, 0])\n",
    "            logger.info('The accuracy of this prediction: ')\n",
    "            logger.info(accuracy)\n",
    "            # print('The accuracy of this prediction: ', accuracy)\n",
    "            # 计算偏差程度\n",
    "            # deviation = np.average(\n",
    "            #     np.abs(test_predict - test_y[:len(test_predict)]) /\n",
    "            #     test_y[:len(test_predict)])\n",
    "            # print('The deviation of this prediction: ', deviation)\n",
    "            # logger.info('The deviation of this prediction: ')\n",
    "            # logger.info(deviation)\n",
    "            # logger.info(np.abs(test_predict - test_y[:len(test_predict)]))\n",
    "            # logger.info(test_y[:len(test_predict)])\n",
    "\n",
    "#             fig = plt.figure()\n",
    "#             fig.set_size_inches(64, 48)\n",
    "#             ax = plt.gca()\n",
    "#             ax.spines['left'].set_linewidth(3)\n",
    "#             ax.spines['bottom'].set_linewidth(3)\n",
    "#             # 设置刻度大小\n",
    "#             rc('xtick', labelsize=40)\n",
    "#             rc('ytick', labelsize=40)\n",
    "#             plt.plot(\n",
    "#                 list(range(len(test_predict))),\n",
    "#                 test_predict,\n",
    "#                 color='blue',\n",
    "#                 label='predict',\n",
    "#             )\n",
    "#             plt.plot(\n",
    "#                 list(range(len(test_y))), test_y, color='red', label='real')\n",
    "#             # 设置图例及X、Y轴标签，label名称支持Tex语法\n",
    "#             plt.legend(loc='best', fontsize=60)\n",
    "#             plt.xlabel(r'$\\rm{dailydata}$', fontdict={'size': 60})\n",
    "#             plt.ylabel(r'$\\rm{fluctuation}$', fontdict={'size': 60})\n",
    "#             plt.savefig(\n",
    "#                 'future_lstm_train{}_accuracy{:.4f}.png'.format(\n",
    "#                     train_times, accuracy),\n",
    "#                 dpi=300)\n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "prediction(time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
