{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import tensorflow as tf\n",
    "from logging_future import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "location = \"C:/Users/workspace/brad_public_workspace_on_win/SH_tongliang/data/数据库/火币日线/\" \n",
    "file = \"11_14_huobi_btcusdt_copy_for_ML.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-11-16 11:17:09,465 INFO in line 140: Number of iterations: 0 , loss: 0.9260706305503845\n",
      "2018-11-16 11:17:09,511 INFO in line 140: Number of iterations: 1 , loss: 0.6805533170700073\n",
      "2018-11-16 11:17:09,553 INFO in line 140: Number of iterations: 2 , loss: 0.49021944403648376\n",
      "2018-11-16 11:17:09,587 INFO in line 140: Number of iterations: 3 , loss: 0.35420963168144226\n",
      "2018-11-16 11:17:09,629 INFO in line 140: Number of iterations: 4 , loss: 0.266570508480072\n",
      "2018-11-16 11:17:09,671 INFO in line 140: Number of iterations: 5 , loss: 0.2180684208869934\n",
      "2018-11-16 11:17:09,705 INFO in line 140: Number of iterations: 6 , loss: 0.19687411189079285\n",
      "2018-11-16 11:17:09,753 INFO in line 140: Number of iterations: 7 , loss: 0.19043506681919098\n",
      "2018-11-16 11:17:09,802 INFO in line 140: Number of iterations: 8 , loss: 0.18842492997646332\n",
      "2018-11-16 11:17:09,837 INFO in line 140: Number of iterations: 9 , loss: 0.18506944179534912\n",
      "model saved:  model_save1/model.ckpt\n",
      "The train has finished\n",
      "INFO:tensorflow:Restoring parameters from model_save1\\model.ckpt\n",
      "2018-11-16 11:17:11,325 INFO in line 186: The accuracy of this prediction: \n",
      "2018-11-16 11:17:11,334 INFO in line 187: 0.46111111111111114\n"
     ]
    }
   ],
   "source": [
    "rnn_unit = 10  # 隐藏层单元数量 ##################调整这个\n",
    "input_size = 3  # 输入个数  \n",
    "output_size = 1  # 输出个数\n",
    "batch_size = 80  # 批量大小  #################调整这个\n",
    "time_step = 20  # 时间步   \n",
    "lr = 0.001  # 学习率\n",
    "# 一般调整隐藏层数量、批量大小及学习率这几个超参数\n",
    "# 输入和输出则由特征量和标签确定\n",
    "# 本例中，以开盘价、最高价、最低价为特征量，\n",
    "# 以收盘价差即涨跌作为标签\n",
    "\n",
    "df = pd.read_csv(location + file, engine=\"python\")\n",
    "pre_data = df.iloc[:, 4].values  # 取收盘价计算标签\n",
    "label = []\n",
    "for i in range(1, len(pre_data)):\n",
    "    label.append(round(pre_data[i] - pre_data[i - 1], 4))\n",
    "\n",
    "df.loc[1:, 'label'] = label\n",
    "data = df.iloc[:, [1, 2, 3, 5]].values  # 获取特征量及标签，类型为np.ndarray\n",
    "# logger.info(data[0:5])\n",
    "\n",
    "train_begin = 0\n",
    "train_end = 200\n",
    "train_times = 10  # 训练次数\n",
    "test_begin = 200\n",
    "test_end = 380\n",
    "\n",
    "\n",
    "def get_train_data(batch_size, time_step, train_begin, train_end):\n",
    "    batch_index = []\n",
    "    data_train = data[train_begin + 1:train_end]\n",
    "    normalized_train_data = (\n",
    "        data_train - np.mean(data_train, axis=0)) / np.std(\n",
    "            data_train, axis=0)\n",
    "    # logger.info('normalized_train_data.shape: ', normalized_train_data.shape)\n",
    "    # logger.info(len(normalized_train_data))\n",
    "    # logger.info(type(normalized_train_data))\n",
    "    # logger.info(len([0, 2]))\n",
    "    # logger.info(normalized_train_data[0:20])\n",
    "    # logger.info(normalized_train_data[0:20, 1])\n",
    "\n",
    "    train_x, train_y = [], []\n",
    "    for i in range(len(normalized_train_data) - time_step):\n",
    "        if i % batch_size == 0:\n",
    "            batch_index.append(i)\n",
    "\n",
    "        x = normalized_train_data[i:i + time_step, :3]\n",
    "        y = normalized_train_data[i:i + time_step, 3, np.newaxis]\n",
    "        train_x.append(x.tolist())\n",
    "        train_y.append(y.tolist())\n",
    "\n",
    "    batch_index.append(len(normalized_train_data) - time_step)\n",
    "    return batch_index, train_x, train_y\n",
    "\n",
    "\n",
    "def get_test_data(time_step, test_begin, test_end):\n",
    "    data_test = data[test_begin:test_end]\n",
    "    test_y = data_test[:, 3]\n",
    "    mean = np.mean(data_test, axis=0)\n",
    "    std = np.std(data_test, axis=0)\n",
    "    normalized_test_data = (data_test - mean) / std\n",
    "    size = (len(normalized_test_data) + time_step - 1) // time_step\n",
    "    test_x, test_y = [], []\n",
    "    for i in range(size - 1):\n",
    "        x = normalized_test_data[i * time_step:(i + 1) * time_step, :3]\n",
    "        y = normalized_test_data[i * time_step:(i + 1) * time_step, 3]\n",
    "        test_x.append(x.tolist())\n",
    "        test_y.extend(y)\n",
    "        # print('type(y): ', type(y))\n",
    "\n",
    "    test_x.append((normalized_test_data[(i + 1) * time_step:, :3]).tolist())\n",
    "    test_y.extend((normalized_test_data[(i + 1) * time_step:, 3]).tolist())\n",
    "    return mean, std, test_x, test_y\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "    'out': tf.Variable(tf.random_normal([rnn_unit, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[\n",
    "        rnn_unit,\n",
    "    ])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[\n",
    "        1,\n",
    "    ]))\n",
    "}\n",
    "\n",
    "\n",
    "# 定义神经网络变量\n",
    "def lstm(X):\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    time_step = tf.shape(X)[1]\n",
    "    w_in = weights['in']\n",
    "    b_in = biases['in']\n",
    "    input_ = tf.reshape(X, [-1, input_size])\n",
    "    # print('input_.shape: ', input_.shape)\n",
    "    input_rnn = tf.matmul(input_, w_in) + b_in\n",
    "    # print('input_rnn.shape: ', input_rnn.shape)\n",
    "    # tensor转换成3维，作为cell的输入\n",
    "    input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit])\n",
    "    # print('input_rnn.shape: ', input_rnn.shape)\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    output_rnn, final_state = tf.nn.dynamic_rnn(\n",
    "        cell, input_rnn, initial_state=init_state, dtype=tf.float32)\n",
    "    output = tf.reshape(output_rnn, [-1, rnn_unit])\n",
    "    w_out = weights['out']\n",
    "    b_out = biases['out']\n",
    "    pred = tf.matmul(output, w_out) + b_out\n",
    "    return pred, final_state\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train_lstm(batch_size, time_step, train_begin, train_end):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "    batch_index, train_x, train_y = get_train_data(batch_size, time_step,\n",
    "                                                   train_begin, train_end)\n",
    "    with tf.variable_scope('future_lstm'):\n",
    "        pred, _ = lstm(X)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.square(tf.reshape(pred, [-1]) - tf.reshape(Y, [-1])))\n",
    "        train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(train_times):\n",
    "                for step in range(len(batch_index) - 1):\n",
    "                    _, loss_ = sess.run(\n",
    "                        [train_operation, loss],\n",
    "                        feed_dict={\n",
    "                            X:\n",
    "                            train_x[batch_index[step]:batch_index[step + 1]],\n",
    "                            Y: train_y[batch_index[step]:batch_index[step + 1]]\n",
    "                        })\n",
    "                # print('Number of iterations: {} , loss: {}'.format(i, loss_))\n",
    "                logger.info('Number of iterations: {} , loss: {}'.format(\n",
    "                    i, loss_))\n",
    "            print('model saved: ', saver.save(sess, 'model_save1/model.ckpt'))\n",
    "            print('The train has finished')\n",
    "\n",
    "\n",
    "train_lstm(batch_size, time_step, train_begin, train_end)\n",
    "\n",
    "\n",
    "def prediction(time_step):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    mean, std, test_x, test_y = get_test_data(time_step, test_begin, test_end)\n",
    "    with tf.variable_scope('future_lstm', reuse=True):\n",
    "        pred, _ = lstm(X)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        with tf.Session() as sess:\n",
    "            model_file = tf.train.latest_checkpoint('model_save1')\n",
    "            saver.restore(sess, model_file)\n",
    "            test_predict = []\n",
    "            for step in range(len(test_x)):\n",
    "                # 一次出time_step个结果，results.shape: (20, 1)\n",
    "                results = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "                # predict = tf.reshape(results, [-1])\n",
    "                predict = results.reshape(-1)\n",
    "                test_predict.extend(predict)\n",
    "\n",
    "            # 还原真实值\n",
    "            test_y = np.array(test_y) * std[3] + mean[3]\n",
    "            test_predict = np.array(test_predict) * std[3] + mean[3]\n",
    "            true_y = test_y\n",
    "            # print('test_predict.shape: ', test_predict.shape)\n",
    "            # print('true_y.shape: ', true_y.shape)\n",
    "            out = np.c_[test_predict, true_y]\n",
    "            out_csv = pd.DataFrame(\n",
    "                data=out, index=None, columns=['prediction', 'true'])\n",
    "            out_csv.to_csv('pred_and_true_20180623.csv')\n",
    "            # 计算精度\n",
    "            right, wrong = 0, 0\n",
    "            calc_data = map(lambda x, y: tuple((x, y)), test_predict,\n",
    "                            test_y[:len(test_predict)])\n",
    "            for data in calc_data:\n",
    "                if data[0] * data[1] > 0 or data[0] == data[1]:\n",
    "                    right += 1\n",
    "                else:\n",
    "                    wrong += 1\n",
    "            accuracy = right / (right + wrong)\n",
    "            \n",
    "            logger.info('The accuracy of this prediction: ')\n",
    "            logger.info(accuracy)\n",
    "            # print('The accuracy of this prediction: ', accuracy)\n",
    "            # 计算偏差程度\n",
    "            # deviation = np.average(\n",
    "            #     np.abs(test_predict - test_y[:len(test_predict)]) /\n",
    "            #     test_y[:len(test_predict)])\n",
    "            # print('The deviation of this prediction: ', deviation)\n",
    "            # logger.info('The deviation of this prediction: ')\n",
    "            # logger.info(deviation)\n",
    "            # logger.info(np.abs(test_predict - test_y[:len(test_predict)]))\n",
    "            # logger.info(test_y[:len(test_predict)])\n",
    "\n",
    "#             fig = plt.figure()\n",
    "#             fig.set_size_inches(64, 48)\n",
    "#             ax = plt.gca()\n",
    "#             ax.spines['left'].set_linewidth(3)\n",
    "#             ax.spines['bottom'].set_linewidth(3)\n",
    "#             # 设置刻度大小\n",
    "#             rc('xtick', labelsize=40)\n",
    "#             rc('ytick', labelsize=40)\n",
    "#             plt.plot(\n",
    "#                 list(range(len(test_predict))),\n",
    "#                 test_predict,\n",
    "#                 color='blue',\n",
    "#                 label='predict',\n",
    "#             )\n",
    "#             plt.plot(\n",
    "#                 list(range(len(test_y))), test_y, color='red', label='real')\n",
    "#             # 设置图例及X、Y轴标签，label名称支持Tex语法\n",
    "#             plt.legend(loc='best', fontsize=60)\n",
    "#             plt.xlabel(r'$\\rm{dailydata}$', fontdict={'size': 60})\n",
    "#             plt.ylabel(r'$\\rm{fluctuation}$', fontdict={'size': 60})\n",
    "#             plt.savefig(\n",
    "#                 'future_lstm_train{}_accuracy{:.4f}.png'.format(\n",
    "#                     train_times, accuracy),\n",
    "#                 dpi=300)\n",
    "#             plt.show()\n",
    "\n",
    "\n",
    "prediction(time_step)"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
