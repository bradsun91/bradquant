{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/SH_Tongliang_Mac_Side/error_log/future_error.log'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-0b8b9c2a04ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlogging_future\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Code_Workspace/brad_public_workspace_mac/SH_Tongliang_Mac_Side/logging_future.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./error_log/future_error.log'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m file_handler = logging.handlers.TimedRotatingFileHandler(\n\u001b[0;32m---> 14\u001b[0;31m     filepath, when='midnight', interval=1, backupCount=10)\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mfile_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetFormatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# 日志输出到控制台\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/logging/handlers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, when, interval, backupCount, encoding, delay, utc, atTime)\u001b[0m\n\u001b[1;32m    197\u001b[0m     \"\"\"\n\u001b[1;32m    198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'h'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackupCount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matTime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mBaseRotatingHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwhen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackupCount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackupCount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/logging/handlers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, encoding, delay)\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0mUse\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstreamed\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \"\"\"\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFileHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, mode, encoding, delay)\u001b[0m\n\u001b[1;32m   1039\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1041\u001b[0;31m             \u001b[0mStreamHandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/logging/__init__.py\u001b[0m in \u001b[0;36m_open\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1068\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresulting\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \"\"\"\n\u001b[0;32m-> 1070\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbaseFilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/miaoyuesun/Code_Workspace/brad_public_workspace_mac/SH_Tongliang_Mac_Side/error_log/future_error.log'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "import tensorflow as tf\n",
    "from logging_future import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/workspace/brad_public_workspace_on_win/SH_tongliang/data/数据库/火币日线/11_14_huobi_btcusdt_copy_for_ML_.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-68e5cf29f4e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"11_14_huobi_btcusdt_copy_for_ML_.csv\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"python\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdata_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtotal_days\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_len\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, doublequote, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    676\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 787\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    788\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1022\u001b[0m                                  ' \"c\", \"python\", or' ' \"python-fwf\")'.format(\n\u001b[1;32m   1023\u001b[0m                                      engine=engine))\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mklass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, **kwds)\u001b[0m\n\u001b[1;32m   2075\u001b[0m         f, handles = _get_handle(f, mode, encoding=self.encoding,\n\u001b[1;32m   2076\u001b[0m                                  \u001b[0mcompression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompression\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2077\u001b[0;31m                                  memory_map=self.memory_map)\n\u001b[0m\u001b[1;32m   2078\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2079\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    401\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mis_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;31m# Python 3 and no explicit encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'replace'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    404\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m             \u001b[0;31m# Python 3 and binary mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/workspace/brad_public_workspace_on_win/SH_tongliang/data/数据库/火币日线/11_14_huobi_btcusdt_copy_for_ML_.csv'"
     ]
    }
   ],
   "source": [
    "location = \"C:/Users/workspace/brad_public_workspace_on_win/SH_tongliang/data/数据库/火币日线/\" \n",
    "file = \"11_14_huobi_btcusdt_copy_for_ML_.csv\"\n",
    "\n",
    "df = pd.read_csv(location + file, engine=\"python\")\n",
    "data_len = len(df)\n",
    "total_days = data_len\n",
    "test_end = total_days\n",
    "train_begin = 0\n",
    "\n",
    "# 参数类别一：\n",
    "\"\"\"\n",
    "保持以下参数不变：\n",
    "\n",
    "利用过去一天: 2018-11-16 0:00, 来预测下一天：\n",
    "time_step = 20\n",
    "rnn_unit = 10  # 隐藏层单元数量 ##################调整这个\n",
    "input_size = 3  # 输入个数  \n",
    "output_size = 1  # 输出个数\n",
    "batch_size = 80  # 批量大小  #################调整这个\n",
    "train_times = 20  # 训练次数\n",
    "lr = 0.001  # 学习率\n",
    "\n",
    "\n",
    "test_train_split 参数调优:\n",
    "\n",
    "test_train_split   accuracy       信号强度\n",
    "       0.2           0.55         -55.86\n",
    "       0.3           0.52         -39.31\n",
    "       0.4           0.4928        -9.88\n",
    "       0.5           0.5111       -28.13\n",
    "       0.6           0.5          -13.87\n",
    "       0.7           0.4961       -27.13\n",
    "       0.8           0.4967       -28.58\n",
    "       0.9           0.5          -9.06\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "test_train_split = 0.5\n",
    "time_step = 20\n",
    "split_batch = int(total_days/time_step) \n",
    "time_step_multiple = int(test_train_split*split_batch)\n",
    "test_begin = int(test_end - (time_step)*time_step_multiple)\n",
    "train_end = test_begin\n",
    "\n",
    "# 这里 test_end - test_begin的差一定要是time_step的倍数\n",
    "print (\"split_batch: \", split_batch)\n",
    "print (\"train_test_split_rate: \", test_train_split)\n",
    "print (\"train_begin: \", train_begin)\n",
    "print (\"train_end: \", train_end)\n",
    "print (\"test_begin: \", test_begin)\n",
    "print (\"test_end: \", test_end)\n",
    "print (\"time_step: \", time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数类别二：\n",
    "tf.reset_default_graph()\n",
    "\n",
    "rnn_unit = 10  # 隐藏层单元数量 ##################调整这个\n",
    "input_size = 3  # 输入个数  \n",
    "output_size = 1  # 输出个数\n",
    "batch_size = 80  # 批量大小  #################调整这个\n",
    "train_times = 20  # 训练次数\n",
    "lr = 0.001  # 学习率\n",
    "# 一般调整隐藏层数量、批量大小及学习率这几个超参数\n",
    "# 输入和输出则由特征量和标签确定\n",
    "# 本例中，以开盘价、最高价、最低价为特征量，\n",
    "# 以收盘价差即涨跌作为标签\n",
    "\n",
    "\n",
    "pre_data = df.iloc[:, 4].values  # 取收盘价计算标签\n",
    "label = []\n",
    "for i in range(1, len(pre_data)):\n",
    "    label.append(round(pre_data[i] - pre_data[i - 1], 4))\n",
    "\n",
    "df.loc[1:, 'label'] = label\n",
    "# df['label'] = df['label'].shift(-1)\n",
    "df.fillna(method='ffill', inplace = True)\n",
    "data = df.iloc[:, [1, 2, 3, 5]].values  # 获取特征量及标签，类型为np.ndarray\n",
    "# logger.info(data[0:5])\n",
    "\n",
    "\n",
    "def get_train_data(batch_size, time_step, train_begin, train_end):\n",
    "    batch_index = []\n",
    "    data_train = data[train_begin + 1:train_end]\n",
    "    normalized_train_data = (\n",
    "        data_train - np.mean(data_train, axis=0)) / np.std(\n",
    "            data_train, axis=0)\n",
    "    # logger.info('normalized_train_data.shape: ', normalized_train_data.shape)\n",
    "    # logger.info(len(normalized_train_data))\n",
    "    # logger.info(type(normalized_train_data))\n",
    "    # logger.info(len([0, 2]))\n",
    "    # logger.info(normalized_train_data[0:20])\n",
    "    # logger.info(normalized_train_data[0:20, 1])\n",
    "\n",
    "    train_x, train_y = [], []\n",
    "    for i in range(len(normalized_train_data) - time_step):\n",
    "        if i % batch_size == 0:\n",
    "            batch_index.append(i)\n",
    "\n",
    "        x = normalized_train_data[i:i + time_step, :3]\n",
    "        y = normalized_train_data[i:i + time_step, 3, np.newaxis]\n",
    "        train_x.append(x.tolist())\n",
    "        train_y.append(y.tolist())\n",
    "\n",
    "    batch_index.append(len(normalized_train_data) - time_step)\n",
    "    return batch_index, train_x, train_y\n",
    "\n",
    "\n",
    "def get_test_data(time_step, test_begin, test_end):\n",
    "    data_test = data[test_begin:test_end]\n",
    "    test_y = data_test[:, 3]\n",
    "    mean = np.mean(data_test, axis=0)\n",
    "    std = np.std(data_test, axis=0)\n",
    "    normalized_test_data = (data_test - mean) / std\n",
    "    size = (len(normalized_test_data) + time_step - 1) // time_step\n",
    "    test_x, test_y = [], []\n",
    "    for i in range(size - 1):\n",
    "        x = normalized_test_data[i * time_step:(i + 1) * time_step, :3]\n",
    "        y = normalized_test_data[i * time_step:(i + 1) * time_step, 3]\n",
    "        test_x.append(x.tolist())\n",
    "        test_y.extend(y)\n",
    "        # print('type(y): ', type(y))\n",
    "\n",
    "    test_x.append((normalized_test_data[(i + 1) * time_step:, :3]).tolist())\n",
    "    test_y.extend((normalized_test_data[(i + 1) * time_step:, 3]).tolist())\n",
    "    return mean, std, test_x, test_y\n",
    "\n",
    "\n",
    "weights = {\n",
    "    'in': tf.Variable(tf.random_normal([input_size, rnn_unit])),\n",
    "    'out': tf.Variable(tf.random_normal([rnn_unit, 1]))\n",
    "}\n",
    "biases = {\n",
    "    'in': tf.Variable(tf.constant(0.1, shape=[\n",
    "        rnn_unit,\n",
    "    ])),\n",
    "    'out': tf.Variable(tf.constant(0.1, shape=[\n",
    "        1,\n",
    "    ]))\n",
    "}\n",
    "\n",
    "\n",
    "# 定义神经网络变量\n",
    "def lstm(X):\n",
    "    batch_size = tf.shape(X)[0]\n",
    "    time_step = tf.shape(X)[1]\n",
    "    w_in = weights['in']\n",
    "    b_in = biases['in']\n",
    "    input_ = tf.reshape(X, [-1, input_size])\n",
    "    # print('input_.shape: ', input_.shape)\n",
    "    input_rnn = tf.matmul(input_, w_in) + b_in\n",
    "    # print('input_rnn.shape: ', input_rnn.shape)\n",
    "    # tensor转换成3维，作为cell的输入\n",
    "    input_rnn = tf.reshape(input_rnn, [-1, time_step, rnn_unit])\n",
    "    # print('input_rnn.shape: ', input_rnn.shape)\n",
    "    cell = tf.nn.rnn_cell.BasicLSTMCell(rnn_unit)\n",
    "    init_state = cell.zero_state(batch_size, dtype=tf.float32)\n",
    "    output_rnn, final_state = tf.nn.dynamic_rnn(\n",
    "        cell, input_rnn, initial_state=init_state, dtype=tf.float32)\n",
    "    output = tf.reshape(output_rnn, [-1, rnn_unit])\n",
    "    w_out = weights['out']\n",
    "    b_out = biases['out']\n",
    "    pred = tf.matmul(output, w_out) + b_out\n",
    "    return pred, final_state\n",
    "\n",
    "\n",
    "# 训练模型\n",
    "def train_lstm(batch_size, time_step, train_begin, train_end):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "    Y = tf.placeholder(tf.float32, shape=[None, time_step, output_size])\n",
    "    batch_index, train_x, train_y = get_train_data(batch_size, time_step,\n",
    "                                                   train_begin, train_end)\n",
    "    with tf.variable_scope('future_lstm'):\n",
    "        pred, _ = lstm(X)\n",
    "        loss = tf.reduce_mean(\n",
    "            tf.square(tf.reshape(pred, [-1]) - tf.reshape(Y, [-1])))\n",
    "        train_operation = tf.train.AdamOptimizer(lr).minimize(loss)\n",
    "        saver = tf.train.Saver(tf.global_variables(), max_to_keep=15)\n",
    "\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "            for i in range(train_times):\n",
    "                for step in range(len(batch_index) - 1):\n",
    "                    _, loss_ = sess.run(\n",
    "                        [train_operation, loss],\n",
    "                        feed_dict={\n",
    "                            X:\n",
    "                            train_x[batch_index[step]:batch_index[step + 1]],\n",
    "                            Y: train_y[batch_index[step]:batch_index[step + 1]]\n",
    "                        })\n",
    "                # print('Number of iterations: {} , loss: {}'.format(i, loss_))\n",
    "                logger.info('Number of iterations: {} , loss: {}'.format(\n",
    "                    i, loss_))\n",
    "#             print('model saved: ', saver.save(sess, 'model_save1/model.ckpt'))\n",
    "            print('The train has finished')\n",
    "\n",
    "\n",
    "train_lstm(batch_size, time_step, train_begin, train_end)\n",
    "\n",
    "\n",
    "def prediction(time_step):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, time_step, input_size])\n",
    "#     print (\"X: \", X)  #brad's peek\n",
    "    mean, std, test_x, test_y = get_test_data(time_step, test_begin, test_end)\n",
    "    with tf.variable_scope('future_lstm', reuse=True):\n",
    "        pred, _ = lstm(X)\n",
    "        saver = tf.train.Saver(tf.global_variables())\n",
    "        with tf.Session() as sess:\n",
    "            model_file = tf.train.latest_checkpoint('model_save1')\n",
    "            saver.restore(sess, model_file)\n",
    "            test_predict = []\n",
    "            # brad's peek:\n",
    "#             print(\"test_x\")\n",
    "#             print (test_x)\n",
    "            for step in range(len(test_x)):\n",
    "                # 一次出time_step个结果，results.shape: (20, 1)\n",
    "                results = sess.run(pred, feed_dict={X: [test_x[step]]})\n",
    "                # predict = tf.reshape(results, [-1])\n",
    "                predict = results.reshape(-1)\n",
    "                test_predict.extend(predict)\n",
    "            # brad's peek:\n",
    "#             print (test_predict)\n",
    "            # 还原真实值\n",
    "            # brad's peek:\n",
    "#             print (\"test_y\",test_y)\n",
    "            test_y = np.array(test_y) * std[3] + mean[3]\n",
    "            test_predict = np.array(test_predict) * std[3] + mean[3]\n",
    "            true_y = test_y\n",
    "            \n",
    "            \n",
    "            # print('test_predict.shape: ', test_predict.shape)\n",
    "            # print('true_y.shape: ', true_y.shape)\n",
    "            out = np.c_[test_predict, true_y]\n",
    "            out_csv = pd.DataFrame(\n",
    "                data=out, index=None, columns=['prediction', 'true'])\n",
    "            out_csv.to_csv('pred_and_true_20180623.csv')\n",
    "            # 计算精度\n",
    "            right, wrong = 0, 0\n",
    "            calc_data = map(lambda x, y: tuple((x, y)), test_predict,\n",
    "                            test_y[:len(test_predict)])\n",
    "            for data in calc_data:\n",
    "                if data[0] * data[1] > 0 or data[0] == data[1]:\n",
    "                    right += 1\n",
    "                else:\n",
    "                    wrong += 1\n",
    "            accuracy = right / (right + wrong)\n",
    "            print(\"利用过去一天: \"+str(df[:test_end].iloc[-1, :].values[0]) + \", 来预测下一天：\")\n",
    "            print (out_csv.iloc[-1, 0])\n",
    "            logger.info('The accuracy of this prediction: ')\n",
    "            logger.info(accuracy)\n",
    "            # print('The accuracy of this prediction: ', accuracy)\n",
    "            # 计算偏差程度\n",
    "            # deviation = np.average(\n",
    "            #     np.abs(test_predict - test_y[:len(test_predict)]) /\n",
    "            #     test_y[:len(test_predict)])\n",
    "            # print('The deviation of this prediction: ', deviation)\n",
    "            # logger.info('The deviation of this prediction: ')\n",
    "            # logger.info(deviation)\n",
    "            # logger.info(np.abs(test_predict - test_y[:len(test_predict)]))\n",
    "            # logger.info(test_y[:len(test_predict)])\n",
    "\n",
    "#             fig = plt.figure()\n",
    "#             fig.set_size_inches(64, 48)\n",
    "#             ax = plt.gca()\n",
    "#             ax.spines['left'].set_linewidth(3)\n",
    "#             ax.spines['bottom'].set_linewidth(3)\n",
    "#             # 设置刻度大小\n",
    "#             rc('xtick', labelsize=40)\n",
    "#             rc('ytick', labelsize=40)\n",
    "#             plt.plot(\n",
    "#                 list(range(len(test_predict))),\n",
    "#                 test_predict,\n",
    "#                 color='blue',\n",
    "#                 label='predict',\n",
    "#             )\n",
    "#             plt.plot(\n",
    "#                 list(range(len(test_y))), test_y, color='red', label='real')\n",
    "#             # 设置图例及X、Y轴标签，label名称支持Tex语法\n",
    "#             plt.legend(loc='best', fontsize=60)\n",
    "#             plt.xlabel(r'$\\rm{dailydata}$', fontdict={'size': 60})\n",
    "#             plt.ylabel(r'$\\rm{fluctuation}$', fontdict={'size': 60})\n",
    "#             plt.savefig(\n",
    "#                 'future_lstm_train{}_accuracy{:.4f}.png'.format(\n",
    "#                     train_times, accuracy),\n",
    "#                 dpi=300)\n",
    "#             plt.show()\n",
    "\n",
    "prediction(time_step)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
