{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from datetime import timedelta\n",
    "import statsmodels.api as sm\n",
    "import csv\n",
    "\n",
    "\"\"\"\n",
    "In this Version 10, all backtester functions are running well, except for the position control, \n",
    "say, even if the portfolio keeps losing money and is going below $0, the strategy is still runnning, \n",
    "which is unrealistic in real life trading situation, which will be solved in Version 11, v11_bt.py \n",
    "\"\"\" \n",
    "# Step one: initialization:\n",
    "\n",
    "# col_strs = [\n",
    "#         \"harvested_at\",\n",
    "#         \"entities.ticker\",\n",
    "#         \"entities.sentiment\",\n",
    "#         \"entities.relevance\"\n",
    "#         \"\"\n",
    "#                 ]\n",
    "# col_dict = {\n",
    "#         col_strs[0]:'timestamp',\n",
    "#         col_strs[1]:'tickers',\n",
    "#         col_strs[2]:'sentiment',\n",
    "#         col_strs[3]:'relevance' \n",
    "#         }\n",
    "\n",
    "\n",
    "# target_file_name = get_raw_csv(file, col_strs, col_dict, '10_11_v4_all_sentiment.csv', None)\n",
    "\n",
    "# file = '/Users/workspace/Accern/database/entity_sentiment_fixed_1.csv'\n",
    "# df = get_raw_csv(file, col_strs, col_dict, '10_12_ken_sentiment_relevance_raw.csv', None)\n",
    "\n",
    "\n",
    "def get_raw_csv(file, col_strs, col_dict, target_file_name, sliced_rows):\n",
    "    usecols = col_strs\n",
    "    print(\"Parsing file: {}\".format(file))\n",
    "    df = pd.read_csv(file,\n",
    "                     engine='c',\n",
    "                     dtype='object',\n",
    "                     skipinitialspace=True,\n",
    "                     quoting=csv.QUOTE_ALL,\n",
    "                     usecols=usecols,\n",
    "                     nrows=sliced_rows)\n",
    "    df.rename(columns=col_dict, inplace=True)\n",
    "    df.to_csv(target_file_name, sep=',', index=False)\n",
    "\n",
    "\n",
    "# This is for extracting and cleaning Accern social media data\n",
    "def clean_extracted(target_file_name, one_ticker, ticker_with_col_str_final):\n",
    "    \n",
    "\n",
    "    #### 4.1.2.1  Delete the UTC and space in the date strings \n",
    "    open_sample = pd.read_csv(target_file_name)\n",
    "    str_dt_list = list(open_sample.date)\n",
    "    for i, s in enumerate(str_dt_list):\n",
    "        str_dt_list[i] = str_dt_list[i].replace(\" UTC\", \"\")\n",
    "    \n",
    "\n",
    "    #### 4.1.2.2 Convert strings into datetime\n",
    "    for i, s in enumerate(str_dt_list):\n",
    "        str_dt_list[i] = datetime.strptime(str_dt_list[i],'%Y-%m-%d %H:%M:%S')\n",
    "    open_sample.index = str_dt_list\n",
    "    del open_sample['date']\n",
    "\n",
    "    #### 4.1.3  Select specific tickers from the sample dataframe\n",
    "    ticker_filtered = open_sample[(open_sample.tickers == one_ticker)]\n",
    "    \n",
    "    #### 4.1.4  Round up the next minute for timestamps \n",
    "    list_ = []\n",
    "    for time_index in ticker_filtered.index:\n",
    "        minute_added = time_index + timedelta(minutes=1)\n",
    "        changed_index = minute_added.replace(hour = minute_added.hour, minute = minute_added.minute, second=0, microsecond=0)\n",
    "        list_.append(changed_index)\n",
    "    ticker_filtered.index = list_\n",
    "    \n",
    "    #### 4.1.5  Drop rows with duplicated timestamps\n",
    "    ticker_filtered['timestamp'] = ticker_filtered.index\n",
    "    ticker_sentiment_minrounded_dropduplicated = ticker_filtered.drop_duplicates('timestamp', keep='last')\n",
    "    \n",
    "    #### 4.1.6  Trim timestamps into only trading hour data\n",
    "    df = []\n",
    "    ts = []\n",
    "    for i, t in enumerate(ticker_sentiment_minrounded_dropduplicated.index):\n",
    "        if ((9, 31) <= (ticker_sentiment_minrounded_dropduplicated.index[i].hour, ticker_sentiment_minrounded_dropduplicated.index[i].minute) < (16, 0)) == True:\n",
    "            item = ticker_sentiment_minrounded_dropduplicated.sentiment[i]\n",
    "            timestamp = ticker_sentiment_minrounded_dropduplicated.index[i]\n",
    "        else:\n",
    "            continue\n",
    "        df.append(item)\n",
    "        ts.append(timestamp)\n",
    "    price_list = df  \n",
    "    trading_ts = ts\n",
    "    ticker_trimmed = pd.DataFrame(price_list, columns=[ticker_with_col_str_final], index = trading_ts)\n",
    "    \n",
    "    return ticker_trimmed\n",
    "\n",
    "\n",
    "def signal_threshold_finder(df, df_col):\n",
    "    signal_col = df[df_col]\n",
    "    print (\"{}'s 10th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.1)))\n",
    "    print (\"{}'s 20th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.2)))\n",
    "    print (\"{}'s 30th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.3)))\n",
    "    print (\"{}'s 40th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.4)))\n",
    "    print (\"{}'s 50th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.5)))\n",
    "    print (\"{}'s 60th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.6)))\n",
    "    print (\"{}'s 70th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.7)))\n",
    "    print (\"{}'s 80th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.8)))\n",
    "    print (\"{}'s 90th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(0.9)))\n",
    "    print (\"{}'s 100th Percentile: {:0.04f}\".format(df_col, signal_col.quantile(1.0)))\n",
    "\n",
    "def signal_threshold_assigner(df, df_col, quantile_value):\n",
    "    signal_col = df[df_col]\n",
    "    return signal_col.quantile(quantile_value)\n",
    "\n",
    "\n",
    "class NewsQuantSignalGeneration(object):\n",
    "\n",
    "    def bool_signal_creation_above(df, df_col_str, ticker_with_signal_str_rdm, max_threshold, bracket_closed):\n",
    "        sentiment_signal_df = pd.DataFrame()\n",
    "        if bracket_closed == False:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if x > max_threshold else 0)\n",
    "        else:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if x >= max_threshold else 0)\n",
    "        return sentiment_signal_df\n",
    "\n",
    "\n",
    "    def bool_signal_creation_below(df, df_col_str, ticker_with_signal_str_rdm, min_threshold, bracket_closed):\n",
    "        sentiment_signal_df = pd.DataFrame()\n",
    "        if bracket_closed == False:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if x < min_threshold else 0)\n",
    "        else:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if x <= min_threshold else 0)\n",
    "        return sentiment_signal_df\n",
    "\n",
    "\n",
    "    def bool_signal_creation_between(df, df_col_str, ticker_with_signal_str_rdm, max_threshold, min_threshold, left_bracket_closed, right_bracket_closed):\n",
    "        sentiment_signal_df = pd.DataFrame()\n",
    "        if left_bracket_closed == True and right_bracket_closed == True:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if min_threshold <= x <= max_threshold else 0)\n",
    "        elif left_bracket_closed == True and right_bracket_closed == False:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if min_threshold <= x < max_threshold else 0)\n",
    "        elif left_bracket_closed == False and right_bracket_closed == True:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if min_threshold < x <= max_threshold else 0)\n",
    "        else: # both are open brackets\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: 1 if min_threshold < x < max_threshold else 0)\n",
    "        return sentiment_signal_df\n",
    "\n",
    "    def bool_signal_creation_outside(df, df_col_str, ticker_with_signal_str_rdm, max_threshold, min_threshold, left_bracket_closed, right_bracket_closed):\n",
    "        sentiment_signal_df = pd.DataFrame()\n",
    "        if left_bracket_closed == True and right_bracket_closed == True:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: -1 if min_threshold >= x else (1 if x >= max_threshold else 0))\n",
    "        elif left_bracket_closed == True and right_bracket_closed == False:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: -1 if min_threshold >= x else (1 if x > max_threshold else 0))\n",
    "        elif left_bracket_closed == False and right_bracket_closed == True:\n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: -1 if min_threshold > x else (1 if x >= max_threshold else 0))\n",
    "        else: \n",
    "            sentiment_signal_df[ticker_with_signal_str_rdm] = df[df_col_str].apply(lambda x: -1 if min_threshold > x else (1 if x > max_threshold else 0))\n",
    "        return sentiment_signal_df\n",
    "\n",
    "\n",
    "# This is for cleaning and processing Accern S&P 500 price data\n",
    "def price_data_process(price_df):\n",
    "    price_df[\"time_index\"] = price_df[\"date\"] + ' ' + price_df[\"timestamp\"]\n",
    "    del price_df['date'], price_df['timestamp']\n",
    "    price_df.index = price_df['time_index']\n",
    "    del price_df['time_index']\n",
    "    price_df_sr = price_df['close_price']\n",
    "\n",
    "    # Convert strings into datetime\n",
    "    str_dt_list = list(price_df.index)\n",
    "    for i, s in enumerate(str_dt_list):\n",
    "        str_dt_list[i] = datetime.strptime(str_dt_list[i],'%Y-%m-%d %H:%M:%S')\n",
    "    price_df.index = str_dt_list\n",
    "    return price_df\n",
    "\n",
    "\n",
    "\n",
    "# Specific strategy signal creation example\n",
    "def ema_crossover(asset_dataframe, slow_ema_window, fast_ema_window, close_price_str):\n",
    "    slow_ema_window = slow_ema_window\n",
    "    fast_ema_window = fast_ema_window\n",
    "    asset_close_sr = asset_dataframe[close_price_str]\n",
    "    slow_ema = series_ema(asset_close_sr, slow_ema_window)\n",
    "    fast_ema = series_ema(asset_close_sr, fast_ema_window)\n",
    "    asset_dataframe['slow_ema'] = slow_ema\n",
    "    asset_dataframe['fast_ema'] = fast_ema\n",
    "    asset_dataframe['diff'] = fast_ema - slow_ema\n",
    "    asset_dataframe['signal'] = asset_dataframe['diff'].apply(lambda x: 1 if x > 0 else 0)\n",
    "    return asset_dataframe\n",
    "\n",
    "\n",
    "def merge_signal_price_files(df1, df2):\n",
    "    df1['ts'] = df1.index\n",
    "    df2['ts'] = df2.index\n",
    "    merged_signal_df = df1.merge(df2, on = 'ts')\n",
    "    merged_signal_df.index = merged_signal_df['ts']\n",
    "    return merged_signal_df\n",
    "\n",
    "\n",
    "def merged_final_signal(merged_signal_df, price_signal_str, sentiment_signal_str, iter_str):\n",
    "    merged_signal_df['final_signal'] = 'Initializing'\n",
    "    for i, item in enumerate(merged_signal_df[iter_str]):\n",
    "        if merged_signal_df[price_signal_str][i] == 1 and merged_signal_df[sentiment_signal_str][i] == 1:\n",
    "            merged_signal_df['final_signal'][i] = 1\n",
    "            print (1, i)\n",
    "\n",
    "        elif merged_signal_df[price_signal_str][i] == 0 and merged_signal_df[sentiment_signal_str][i] == 0:\n",
    "            merged_signal_df['final_signal'][i] = 0\n",
    "            print (0, i)\n",
    "\n",
    "        else: # nothing changed, update this ts data as to be the previous one:\n",
    "            # notice here, if i == 0 in this case, i-1 from below won't run, so analyze different scenarios:\n",
    "            if i == 0: \n",
    "                continue\n",
    "            else:\n",
    "                merged_signal_df['final_signal'][i] = merged_signal_df['final_signal'][i-1]\n",
    "                print (\"{}\".format(merged_signal_df['final_signal'][i-1]), i)\n",
    "    return merged_signal_df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class PortfolioCalculation(object):\n",
    "\n",
    "    \"\"\"\n",
    "    The purpose of building this class is to define the quantity and profit functions we will be calling in the backtesting\n",
    "    process, where quantity(bp, ticker_price, port_pct) means the position size we hold in our strategy; while \n",
    "    profit(x0, x1, quantity, direction = 'L') means each time how much we make for each round of our trade, where x0 means \n",
    "    the previous stock price, x1 means the current stock price\n",
    "    \"\"\"\n",
    "    \n",
    "    def quantity(bp, ticker_price, port_pct): \n",
    "        ticker_quant = bp*port_pct/ticker_price\n",
    "        return ticker_quant\n",
    "\n",
    "    def profit(x0, x1, quantity, direction = 'L'):\n",
    "        \"\"\"direction = 'L' means when we calculate each profit, we go long, if we want to go short for each trade we put \n",
    "        direction = 'S'\n",
    "        \"\"\"\n",
    "        p = (x1 - x0) * int(quantity)\n",
    "        if direction == 'L':\n",
    "            return p\n",
    "        elif direction == 'S':\n",
    "            return -p\n",
    "        else:\n",
    "            raise ValueError('At least put one strategy direction here!')\n",
    "\n",
    "\n",
    "def ib_equity_commissions(quantity, fill_price):\n",
    "    \"\"\"\n",
    "    Calculate the Interactive Brokers commission for\n",
    "    a transaction. This is based on the US Fixed pricing,\n",
    "    the details of which can be found here:\n",
    "    https://www.interactivebrokers.co.uk/en/index.php?f=1590&p=stocks1\n",
    "    \"\"\"\n",
    "    commission = min(0.005 * fill_price * quantity, max(1.0, 0.005 * quantity)) \n",
    "    return commission\n",
    "\n",
    "\n",
    "class BT(object):\n",
    "    \"\"\"\n",
    "    This is the meat of the whole backtesting infrastructure, mainly to prepare the final dataframe with all \n",
    "    important columns, including pnl and all stuff.\n",
    "    \n",
    "    In this version of updates, following bugs and problems are fixed from previous version of BT class:\n",
    "    \n",
    "    1. previous versions' signal change lags one row behind\n",
    "    2. previous versions didn't factor into comissions and all other important trade and market impact stats \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, port_utilization, tradable_capital, margin_leverage):\n",
    "        self.data = []\n",
    "        self.tradable_capital = tradable_capital\n",
    "        self.margin_leverage = margin_leverage\n",
    "        self.port_utilization = port_utilization\n",
    "        self.volume_limit = 0.025 ############# default = 0.025 as the quantopian standard when initializing.\n",
    "        self.price_impact_constant = 0.1  ############# default = 0.1 as the quantopian standard when initializing.\n",
    "        self.price_impact_constant = 0.1\n",
    "        \"\"\"\n",
    "        The price impact constant (default 0.1) defines how large of an impact the order will have on the backtester's price calculation. \n",
    "        The slippage is calculated by multiplying the price impact constant (default = 0.1) by the square of the ratio of the order to the total volume. \n",
    "        In Quantopian previous example, for the 25-share orders, the price impact is 0.1 * (25/1000) * (25/1000), or 0.00625%. For the 10-share order, \n",
    "        the price impact is 0.1 * (10/1000) * (10/1000), or 0.001%.\n",
    "        \n",
    "        Reference page:\n",
    "        https://www.quantopian.com/help#ide-slippage\n",
    "        \"\"\"\n",
    "\n",
    "    def core_backtester(self, signal_dataframe, df_sgnl_str, df_tkr_price_str, strategy_drct, \n",
    "                        long_short_both, enter_signal, exit_signal, long_signal, short_signal):\n",
    "        \n",
    "        signal_updates = signal_dataframe[df_sgnl_str]\n",
    "        ticker_price_updates = signal_dataframe[df_tkr_price_str]\n",
    "        init_signal = 0\n",
    "        init_ticker_qty = 0\n",
    "        init_port_value = 0 \n",
    "        init_ticker_price = 0\n",
    "        init_mkt_qty = 0\n",
    "        init_mkt_volume = 0\n",
    "        cum_trades = 0\n",
    "        cum_commissions = 0\n",
    "        each_commission_cost = 0,\n",
    "        volume_impact_pct = 0\n",
    "        filled_price_impact_pct = 0\n",
    "        filled_price_impact_abs = 0\n",
    "        filled_price_impact_chg_dlr = 0 \n",
    "        actual_filled_price = 0\n",
    "        exited = False\n",
    "        \n",
    "########################\n",
    "###### Scenario Situation 1/2 - single-dirction strategy\n",
    "\n",
    "        if long_short_both == False: # there's only one trading direction:\n",
    "        \n",
    "            for i, (ts, signl) in enumerate(signal_updates.items()):            \n",
    "                # update each profit and initital ticker price\n",
    "                if i:\n",
    "                    each_profit = PortfolioCalculation.profit(init_ticker_price, ticker_price_updates[ts], abs(init_ticker_qty), strategy_drct)\n",
    "                else:\n",
    "                    each_profit = 0  \n",
    "                init_ticker_price = ticker_price_updates[ts]\n",
    "                \n",
    "                # discuss if the signal changes: \n",
    "                if signl != init_signal:   #signal starts to change, meaning we need to enter or exit positions\n",
    "                    \n",
    "                    if signl == enter_signal:  #only need to update position's qty here\n",
    "                        updated_qty = signl*PortfolioCalculation.quantity(self.tradable_capital, ticker_price_updates[ts], self.port_utilization) ################## 'ticker_qty' that the commission package needs\n",
    "                        entered = True\n",
    "                        init_ticker_qty = updated_qty \n",
    "                        cum_trades = 1 + cum_trades\n",
    "                        filled_price_impact_pct = (self.price_impact_constant)*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])\n",
    "                        filled_price_impact_abs = (self.price_impact_constant)*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "                        filled_price_impact_chg_dlr = filled_price_impact_abs if strategy_drct == 'L' else (-filled_price_impact_abs if strategy_drct == 'S' else 0) \n",
    "                        actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price\n",
    "                        each_commission_cost = ib_equity_commissions(abs(init_ticker_qty), ticker_price_updates[ts])\n",
    "                        cum_commissions += each_commission_cost \n",
    "                        \n",
    "                        \n",
    "                    elif signl == exit_signal:\n",
    "                        updated_qty = PortfolioCalculation.quantity(self.tradable_capital, ticker_price_updates[ts], self.port_utilization) ################## 'ticker_qty' that the commission package needs\n",
    "                        exited = True\n",
    "                        init_ticker_qty = updated_qty\n",
    "                        cum_trades = 1 + cum_trades\n",
    "                        filled_price_impact_pct = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])\n",
    "                        filled_price_impact_abs = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "                        filled_price_impact_chg_dlr = filled_price_impact_abs if strategy_drct == 'L' else (-filled_price_impact_abs if strategy_drct == 'S' else 0) \n",
    "                        actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price\n",
    "                        each_commission_cost = ib_equity_commissions(abs(updated_qty), ticker_price_updates[ts])\n",
    "                        cum_commissions += each_commission_cost                        \n",
    "                        init_ticker_qty = 0 \n",
    "                        \n",
    "                    \n",
    "                if exited:             # if there's no position, update qty back to 0\n",
    "                    init_ticker_qty = 0\n",
    "            \n",
    "                    exited = False     # update exit status back to initialization of being False, cannot change to True or the traded qty in position will be all 0\n",
    "#                     init_signal = signl\n",
    "#                     cum_trades = cum_trades\n",
    "#                     volume_impact_pct = init_ticker_qty/signal_dataframe['total_quantity'][ts]\n",
    "#                     ################# Adding fourth trade stats: \n",
    "#                     filled_price_impact_pct = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])\n",
    "#                     ################# Adding fifth trade stats: \n",
    "#                     filled_price_impact_abs = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "#                     ################# Adding sixth trade stats:\n",
    "#                     filled_price_impact_chg_dlr = filled_price_impact_abs if strategy_drct == 'L' else (-filled_price_impact_abs if strategy_drct == 'S' else 0) \n",
    "#                     ################# Adding seventh trade stats:\n",
    "#                     actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price\n",
    "                    \n",
    "            \n",
    "                each_row = {\n",
    "                    'timestamp':ts, # save updated index\n",
    "                    'ticker_price':ticker_price_updates[ts], # save updated price\n",
    "                    'signal':signl, \n",
    "                    'ticker_qty':int(init_ticker_qty), # save updated qty\n",
    "                    'profit':each_profit, # save updated profit\n",
    "                    'cum_trades':cum_trades, \n",
    "                    'commissions':each_commission_cost,\n",
    "                    'cum_commissions': cum_commissions,\n",
    "                    'mkt_qty':signal_dataframe['total_quantity'][ts],\n",
    "                    'mkt_volume':signal_dataframe['total_volume'][ts],\n",
    "                    'volume_impact_pct':int(init_ticker_qty)/signal_dataframe['total_quantity'][ts],\n",
    "                    'filled_price_impact_pct':filled_price_impact_pct,\n",
    "                    'filled_price_impact_abs':filled_price_impact_abs,\n",
    "                    'filled_price_impact_chg_dlr':filled_price_impact_chg_dlr, \n",
    "                    'actual_filled_price': actual_filled_price\n",
    "                }\n",
    "\n",
    "                self.data.append(each_row)\n",
    "                init_signal = signl\n",
    "                 # At last, update the signal_0 to this row's signal, which is 'signl'\n",
    "\n",
    "            data_df = pd.DataFrame(self.data)\n",
    "            data_df.index = data_df['timestamp']\n",
    "\n",
    "            # Connect data_df with the later df2:\n",
    "\n",
    "\n",
    "\n",
    "            # copy df1 to df2, creating a new dataframe for storing tearsheet data for printing\n",
    "            df2 = data_df\n",
    "#             df2['each_profit'] = data_df['profit']\n",
    "            df2['cum_profit'] = data_df.profit.cumsum() + self.tradable_capital\n",
    "            df2['each_return_pct'] = df2.cum_profit.pct_change().fillna(0)\n",
    "            df2['cum_return_pct'] = (df2['each_return_pct'] + 1).cumprod()\n",
    "            df2['net_cum_profit'] = df2['cum_profit'] - df2['cum_commissions'] - df2['filled_price_impact_abs'].cumsum()\n",
    "            df2['net_each_return_pct'] = df2['net_cum_profit'].pct_change().fillna(0)\n",
    "            df2['net_cum_return_pct'] = (df2['net_each_return_pct'] + 1).cumprod()\n",
    "            df2['commission_fees_impact_level'] = df2['cum_commissions']/df2['cum_profit']\n",
    "\n",
    "            \n",
    "            df2 = df2.dropna(0)\n",
    "            \n",
    "            \n",
    "            \n",
    "########################\n",
    "###### Strategy Scenario Situation 2/2 - both-direction strategy:  \n",
    "\n",
    "        elif long_short_both == True:\n",
    "            strategy_drct = None\n",
    "            for i, (ts, signl) in enumerate(signal_updates.items()):\n",
    "                if i and strategy_drct != None:\n",
    "                    each_profit = PortfolioCalculation.profit(init_ticker_price, ticker_price_updates[ts], abs(init_ticker_qty), strategy_drct)\n",
    "                else:\n",
    "                    each_profit = 0  \n",
    "                init_ticker_price = ticker_price_updates[ts]\n",
    "                \n",
    "                # Normally, the signal switches from 1 to 0 and then to -1, and vice versa, but another situation will not be avoided where signal will be changed directly changed from 1 to -1 or vice versa.\n",
    "                \n",
    "                if signl != init_signal: \n",
    "                    \n",
    "                    if signl == long_signal: \n",
    "                        updated_qty = PortfolioCalculation.quantity(self.tradable_capital, ticker_price_updates[ts], self.port_utilization)\n",
    "                        entered = True\n",
    "                        init_ticker_qty = updated_qty\n",
    "                        cum_trades = 1 + cum_trades   \n",
    "                        filled_price_impact_pct = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])\n",
    "                        filled_price_impact_abs = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "                        drct = 'L'\n",
    "                        filled_price_impact_chg_dlr = filled_price_impact_abs if strategy_drct == 'L' else 0\n",
    "                        actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price                    \n",
    "                        each_commission_cost = ib_equity_commissions(abs(updated_qty), ticker_price_updates[ts])\n",
    "                        cum_commissions += each_commission_cost\n",
    "                           \n",
    "                    \n",
    "                    elif signl == short_signal:\n",
    "                        updated_qty = signl*PortfolioCalculation.quantity(self.tradable_capital, ticker_price_updates[ts], self.port_utilization)\n",
    "                        entered = True\n",
    "                        init_ticker_qty = updated_qty\n",
    "                        cum_trades = 1 + cum_trades \n",
    "                        filled_price_impact_pct = (self.price_impact_constant)*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])\n",
    "                        filled_price_impact_abs = (self.price_impact_constant)*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])*(abs(init_ticker_qty)/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "                        drct = 'S'\n",
    "                        filled_price_impact_chg_dlr = -filled_price_impact_abs if strategy_drct == 'S' else 0\n",
    "                        actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price                    \n",
    "                        each_commission_cost = ib_equity_commissions(abs(updated_qty), ticker_price_updates[ts])\n",
    "                        cum_commissions += each_commission_cost\n",
    "                        \n",
    "                    \n",
    "                    # Closing the position in this case is trickier since we need to dicuss which direction to need close against\n",
    "                    elif signl == exit_signal:\n",
    "                        if init_signal == 1: #  if we need to close the position by selling the long position, the trade direction is \"S\"\n",
    "                            updated_qty = PortfolioCalculation.quantity(self.tradable_capital, ticker_price_updates[ts], self.port_utilization)\n",
    "                            exited = True\n",
    "                            init_ticker_qty = updated_qty\n",
    "                            cum_trades = 1 + cum_trades \n",
    "                            filled_price_impact_pct = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])\n",
    "                            filled_price_impact_abs = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "                            drct = 'S'\n",
    "                            filled_price_impact_chg_dlr = -filled_price_impact_abs if strategy_drct == 'S' else 0\n",
    "                            actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price\n",
    "                            each_commission_cost = ib_equity_commissions(abs(updated_qty), ticker_price_updates[ts])\n",
    "                            cum_commissions += each_commission_cost\n",
    "                            init_ticker_qty = 0\n",
    "                            \n",
    "                            \n",
    "                        elif init_signal == -1: #  if we need to close the position by buying back the short position, the trade direction is \"L\"\n",
    "                            updated_qty = PortfolioCalculation.quantity(self.tradable_capital, ticker_price_updates[ts], self.port_utilization)\n",
    "                            exited = True\n",
    "                            init_ticker_qty = updated_qty\n",
    "                            cum_trades = 1 + cum_trades \n",
    "                            filled_price_impact_pct = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])\n",
    "                            filled_price_impact_abs = (self.price_impact_constant)*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*(init_ticker_qty/signal_dataframe['total_quantity'][ts])*init_ticker_price\n",
    "                            drct = 'L'\n",
    "                            filled_price_impact_chg_dlr = filled_price_impact_abs if strategy_drct == 'L' else 0\n",
    "                            actual_filled_price = filled_price_impact_chg_dlr + init_ticker_price\n",
    "                            each_commission_cost = ib_equity_commissions(abs(updated_qty), ticker_price_updates[ts])\n",
    "                            cum_commissions += each_commission_cost\n",
    "                            init_ticker_qty = 0\n",
    "                        \n",
    "                    strategy_drct = drct\n",
    "                    \n",
    "                    \n",
    "\n",
    "                if exited:             # if there's no position, update qty back to 0\n",
    "                    exited = False \n",
    "                    init_ticker_qty = 0\n",
    "                        # update exit status back to initialization of being False, cannot change to True or the traded qty in position will be all 0 \n",
    "                    \n",
    "\n",
    "                    \n",
    "                each_row = {\n",
    "                    'timestamp':ts, # save updated index\n",
    "                    'ticker_price':ticker_price_updates[ts], # save updated price\n",
    "                    'signal':signl, # save previous signal\n",
    "                    'ticker_qty':int(init_ticker_qty), # save updated qty\n",
    "                    'profit':each_profit, # save updated profit\n",
    "                     ################## Add more details regarding the trading stats and market impact.\n",
    "                    'cum_trades':cum_trades, \n",
    "                    'commissions':each_commission_cost,\n",
    "                    'cum_commissions': cum_commissions,\n",
    "                    'mkt_qty':signal_dataframe['total_quantity'][ts],\n",
    "                    'mkt_volume':signal_dataframe['total_volume'][ts],\n",
    "#                     'volume_impact_pct':volume_impact_pct,\n",
    "                    'volume_impact_pct':int(init_ticker_qty)/signal_dataframe['total_quantity'][ts],\n",
    "                    'filled_price_impact_pct':filled_price_impact_pct,\n",
    "                    'filled_price_impact_abs':filled_price_impact_abs,\n",
    "                    'filled_price_impact_chg_dlr':filled_price_impact_chg_dlr, \n",
    "                    'actual_filled_price': actual_filled_price,\n",
    "                }\n",
    "\n",
    "                self.data.append(each_row)\n",
    "                init_signal = signl \n",
    "                 # At last, update the signal_0 to this row's signal, which is 'signl'\n",
    "\n",
    "            data_df = pd.DataFrame(self.data)\n",
    "            data_df.index = data_df['timestamp']\n",
    "\n",
    "\n",
    "            # copy df1 to df2, creating a new dataframe for storing tearsheet data for printing\n",
    "            df2 = data_df\n",
    "#             df2['each_profit'] = data_df['profit']\n",
    "            df2['cum_profit'] = data_df.profit.cumsum() + self.tradable_capital\n",
    "            df2['each_return_pct'] = df2.cum_profit.pct_change().fillna(0)\n",
    "            df2['cum_return_pct'] = (df2['each_return_pct'] + 1).cumprod()\n",
    "            df2['net_cum_profit'] = df2['cum_profit'] - df2['cum_commissions'] - df2['filled_price_impact_abs'].cumsum()\n",
    "            df2['net_each_return_pct'] = df2['net_cum_profit'].pct_change().fillna(0)\n",
    "            df2['net_cum_return_pct'] = (df2['net_each_return_pct'] + 1).cumprod()\n",
    "            df2['commission_fees_impact_level'] = df2['cum_commissions']/df2['cum_profit']\n",
    "\n",
    "            df2 = df2.dropna(0)\n",
    "            \n",
    "        return df2\n",
    "\n",
    "\n",
    "\n",
    "class RiskMetrics(object):\n",
    "    '''\n",
    "    The purpose of building this RiskMetrics class is to calculate and prep various risk metrics for us to call   \n",
    "    '''\n",
    "    ##### 1. Gross Sharpe & Net Sharpe (Done) #####   \n",
    "\n",
    "    def annualized_sharpe_ratio(strategy_ret, freq_multiplier):\n",
    "        \"\"\"\n",
    "        Documentation:\n",
    "        ---------\n",
    "        Strategy_ret: Series | Numpy Array\n",
    "        Freq_multiplier explanation: below are the time series frequency we get for our data with its corresponding frequency\n",
    "        multiplier we will be using, so that we can deal with any frequency of data, from second to daily data. Created by Brad. \n",
    "        \n",
    "        Monthly_Data_Freq_multiplier: 12\n",
    "        Weekly_Data_Freq_multiplier: 52\n",
    "        Daily_Data_Freq_multiplier: 252, \n",
    "        Hourly_Data_Freq_multiplier: 252*6.5,  \n",
    "        Minutely_Data_Freq_multipler: 252*6.5*60 \n",
    "        Second_Data_Freq_multipler: 252*6.5*60*60\n",
    "        \"\"\"\n",
    "        er = np.mean(strategy_ret)\n",
    "        return np.sqrt(freq_multiplier) * er / np.std(strategy_ret, ddof=1)\n",
    "\n",
    "    def sharpe_ratio_with_any_freq_ts(strategy_ret):\n",
    "        er = np.mean(strategy_ret)\n",
    "        return er / np.std(strategy_ret, ddof=1)\n",
    "\n",
    "\n",
    "    def net_sharpe_ratio(net_each_return_pct, freq_multiplier):\n",
    "        er = np.mean(net_each_return_pct)\n",
    "        return np.sqrt(freq_multiplier) * er / np.std(net_each_return_pct, ddof=1)\n",
    "\n",
    "\n",
    "    ##### 2. Gross Sortino & Net Sortino (Done) #####\n",
    "\n",
    "    def sortino_ratio_with_any_freq_ts(strategy_ret):\n",
    "        r = np.asarray(strategy_ret)\n",
    "        diff = (0 - r).clip(min=0)\n",
    "        downside_std =  ((diff**2).sum() / diff.shape[0])**(1/2)\n",
    "        er = np.mean(strategy_ret)\n",
    "        return er / downside_std\n",
    "\n",
    "    def annualized_sortino_ratio(strategy_ret, freq_multiplier):\n",
    "        \"\"\"\n",
    "        Documentation:\n",
    "        ---------\n",
    "        Strategy_ret: Series | Numpy Array  \n",
    "        Freq_multiplier explanation: same as above in the sharpe ratio part: \n",
    "        Daily_Data_Freq_multiplier: 252, \n",
    "        Hourly_Data_Freq_multiplier: 252*6.5,  \n",
    "        Minutely_Data_Freq_multipler: 252*6.5*60, \n",
    "        Second_Data_Freq_multipler: 252*6.5*60*60\n",
    "        \"\"\"\n",
    "\n",
    "        r = np.asarray(strategy_ret)\n",
    "        diff = (0 - r).clip(min=0)\n",
    "        downside_std =  ((diff**2).sum() / diff.shape[0])**(1/2)\n",
    "        er = np.mean(strategy_ret)\n",
    "        return np.sqrt(freq_multiplier) * er / downside_std\n",
    "\n",
    "    def net_sortino_ratio(net_each_return_pct, freq_multiplier):\n",
    "        r = np.asarray(net_each_return_pct)\n",
    "        diff = (0 - r).clip(min=0)\n",
    "        downside_std =  ((diff**2).sum() / diff.shape[0])**(1/2)\n",
    "        er = np.mean(net_each_return_pct)\n",
    "        return np.sqrt(freq_multiplier) * er / downside_std\n",
    "\n",
    "\n",
    "\n",
    "    ##### 3. Gross Alpha Beta & Net Alpha Beta (Done) #####\n",
    "\n",
    "    def alpha_beta(strategy_ret, benchmark_ret, benchmark_str, show_all):\n",
    "        # set benchmark's constant\n",
    "        X = sm.add_constant(benchmark_ret) \n",
    "        # y is the values of returns of the strategy\n",
    "        y = strategy_ret\n",
    "\n",
    "        # creating the Ordinary Least Square model to get beta and alpha between strategy and benchmark return\n",
    "        model = sm.OLS(y,X).fit()\n",
    "        beta = model.params[benchmark_str]\n",
    "        alpha = model.params[\"const\"]\n",
    "        # If we want to see all stats summary table and graph, we make show_all == True, \n",
    "        # otherwise it will only return alpha and beta.\n",
    "        if show_all == False:\n",
    "            print (\"Gross Jensen's Constant: {:0.04f}\".format(alpha))\n",
    "            print ('Gross Beta Against Benchmark: {:0.04f}'.format(beta))\n",
    "        else:\n",
    "            print (\"Gross Jensen's Constant: {:0.04f}\".format(alpha))\n",
    "            print ('Gross Beta Against Benchmark: {:0.04f}'.format(beta))\n",
    "            print (model.summary())\n",
    "\n",
    "            # If show_all == True, prep for the alpha beta graph\n",
    "            fig, ax1 = plt.subplots(1,figsize=(30,6))\n",
    "            ax1.scatter(benchmark_ret, strategy_ret,label= \"Gross Strategy Returns\", color='blue', edgecolors='none', alpha=0.7)\n",
    "            ax1.grid(True)\n",
    "            ax1.set_xlabel(\"Benchmark's Returns\")\n",
    "            ax1.set_ylabel(\"Gross Strategy's Returns\")\n",
    "\n",
    "            # create X points of the line, by using the min and max points to generate sequence\n",
    "            line_x = np.linspace(benchmark_ret.min(), benchmark_ret.max())\n",
    "\n",
    "            # generate y points by multiplying x by the slope\n",
    "            ax1.plot(line_x, line_x*model.params[benchmark_str], color=\"red\", label=\"beta\")\n",
    "\n",
    "            # add legend\n",
    "            ax1.legend(loc='upper center', ncol=2, fontsize='large')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    def net_alpha_beta(net_each_return_pct, benchmark_ret, benchmark_str, show_all):\n",
    "\n",
    "        # set benchmark's constant\n",
    "        X = sm.add_constant(benchmark_ret) \n",
    "        # y is the values of returns of the strategy\n",
    "        y = net_each_return_pct\n",
    "\n",
    "        # creating the Ordinary Least Square model to get beta and alpha between strategy and benchmark return\n",
    "        model = sm.OLS(y,X).fit()\n",
    "        beta = model.params[benchmark_str]\n",
    "        alpha = model.params[\"const\"]\n",
    "        # If we want to see all stats summary table and graph, we make show_all == True, \n",
    "        # otherwise it will only return alpha and beta.\n",
    "        if show_all == False:\n",
    "            print (\"Net Jensen's Constant: {:0.04f}\".format(alpha))\n",
    "            print ('Net Beta Against Benchmark: {:0.04f}'.format(beta))\n",
    "        else:\n",
    "            print (\"Net Jensen's Constant: {:0.04f}\".format(alpha))\n",
    "            print ('Net Beta Against Benchmark: {:0.04f}'.format(beta))\n",
    "            print (model.summary())\n",
    "\n",
    "            # If show_all == True, prep for the alpha beta graph\n",
    "            fig, ax1 = plt.subplots(1,figsize=(30,6))\n",
    "            ax1.scatter(benchmark_ret, net_each_return_pct,label= \"Net Strategy Returns\", color='blue', edgecolors='none', alpha=0.7)\n",
    "            ax1.grid(True)\n",
    "            ax1.set_xlabel(\"Benchmark's Returns\")\n",
    "            ax1.set_ylabel(\"Net Strategy's Returns\")\n",
    "\n",
    "            # create X points of the line, by using the min and max points to generate sequence\n",
    "            line_x = np.linspace(benchmark_ret.min(), benchmark_ret.max())\n",
    "\n",
    "            # generate y points by multiplying x by the slope\n",
    "            ax1.plot(line_x, line_x*model.params[benchmark_str], color=\"red\", label=\"beta\")\n",
    "\n",
    "            # add legend\n",
    "            ax1.legend(loc='upper center', ncol=2, fontsize='large')\n",
    "\n",
    "            plt.show()\n",
    "\n",
    "\n",
    "    ##### 4. Gross gain loss ratio & Net gain loss ratio (Done) #####\n",
    "\n",
    "    def gain_loss_ratio(strategy_ret):\n",
    "        \"\"\"Upside Performnace vs. Downside Performance\n",
    "\n",
    "        Lower than 1: Upside movement is less than Downside movement\n",
    "        Higher than 1: Upside movement is less than Downside movement\n",
    "        \"\"\"\n",
    "        r = np.asarray(strategy_ret)\n",
    "        diff_dn = (0 - r).clip(min = 0)\n",
    "        diff_up = (r - 0).clip(min = 0)\n",
    "        downside_std =  ((diff_dn**2).sum() / diff_dn.shape[0])**(1/2)\n",
    "        upside_std = ((diff_up**2).sum() / diff_up.shape[0])**(1/2)\n",
    "        return upside_std / downside_std\n",
    "\n",
    "\n",
    "    def net_gain_loss_ratio(net_each_return_pct):\n",
    "        \"\"\"Upside Performnace vs. Downside Performance\n",
    "\n",
    "        Lower than 1: Upside movement is less than Downside movement\n",
    "        Higher than 1: Upside movement is less than Downside movement\n",
    "        \"\"\"\n",
    "        r = np.asarray(net_each_return_pct)\n",
    "        diff_dn = (0 - r).clip(min = 0)\n",
    "        diff_up = (r - 0).clip(min = 0)\n",
    "        downside_std =  ((diff_dn**2).sum() / diff_dn.shape[0])**(1/2)\n",
    "        upside_std = ((diff_up**2).sum() / diff_up.shape[0])**(1/2)\n",
    "        return upside_std / downside_std\n",
    "\n",
    "\n",
    "    ##### 5. Gross water mark & Net water mark (Done) #####\n",
    "\n",
    "    def water_mark(pnl, how='high'):\n",
    "        \"\"\"Accumulative Maximum/Minimum of a Series\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        pnl: Pandas Series\n",
    "            - index of timestamp\n",
    "            - period percentagized returns\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        Series\n",
    "        \"\"\"\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        return mark.accumulate(pnl.fillna(pnl.min()))\n",
    "\n",
    "\n",
    "    def net_water_mark(net_cum_return_pct, how='high'):\n",
    "        \"\"\"Accumulative Maximum/Minimum of a Series\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        pnl: Pandas Series\n",
    "            - index of timestamp\n",
    "            - period percentagized returns\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        Series\n",
    "        \"\"\"\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        return mark.accumulate(net_cum_return_pct.fillna(net_cum_return_pct.min()))\n",
    "\n",
    "\n",
    "    ##### 6. Gross DD & Net DD (Done) #####\n",
    "\n",
    "    def drawdown(pnl, how='high'):\n",
    "        \"\"\"\n",
    "        - Calcualte the largest peak-to-through drawdown of the PnL Curve\n",
    "        - As well as the Duration of the drawdown\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        pnl: Pandas Series \n",
    "            - index of timestamp\n",
    "            - period percentagized returns\n",
    "\n",
    "        Return\n",
    "        ------\n",
    "        drawdown\n",
    "        \"\"\"\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        watermark = mark.accumulate(pnl.fillna(pnl.min()))\n",
    "        dd = 1 - (pnl / watermark.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        return dd\n",
    " \n",
    "    def net_drawdown_dur(net_cum_return_pct, how = 'high'):    \n",
    "        \"\"\"Accumulative Drawdown Duration\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        pnl: Pandas Series \n",
    "        - index of timestamp\n",
    "        - period percentagized returns\n",
    "\n",
    "\n",
    "        Theory\n",
    "        ------\n",
    "        1. Get the Drawdown percentage series\n",
    "        2. Convert anything that is not 0 to 1 as boolean type\n",
    "        3. Then find periodic drawdown period\n",
    "        - by comparising on changing in boolean value\n",
    "        - cumsum to get a series that is labeled with drawdown period\n",
    "        4. Group by each drawdown period using count size\n",
    "\n",
    "        Return\n",
    "        -------\n",
    "        Integer, maximum period of drawdown period length\n",
    "        \"\"\"\n",
    "        # Get Drawdown Max Duration\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        watermark = mark.accumulate(net_cum_return_pct.fillna(net_cum_return_pct.min()))\n",
    "        dd = 1 - (net_cum_return_pct / watermark.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        drawdown = dd\n",
    "        sr = drawdown[1:].astype(bool)\n",
    "        return sr.groupby((sr != sr.shift()).cumsum()).size()\n",
    "\n",
    "    ##### 7. Gross max_DD & Net max_DD (Done) #####\n",
    "\n",
    "    def max_drawdown(pnl, how ='high'):\n",
    "        \"\"\"Max drawdown Percentage in the trading period\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        pnl: Pandas Series \n",
    "            - index of timestamp\n",
    "            - period percentagized returns\n",
    "\n",
    "        Rerturn\n",
    "        -------\n",
    "        FLoat, maximum drawdown percentage\n",
    "        \"\"\"\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        watermark = mark.accumulate(pnl.fillna(pnl.min()))\n",
    "        dd = 1 - (pnl / watermark.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        drawdown = dd\n",
    "        return drawdown.max()\n",
    "\n",
    "\n",
    "    def net_max_drawdown(net_cum_return_pct, how ='high'):\n",
    "        \"\"\"Max drawdown Percentage in the trading period\n",
    "\n",
    "        Parameter\n",
    "        ---------\n",
    "        pnl: Pandas Series \n",
    "            - index of timestamp\n",
    "            - period percentagized returns\n",
    "\n",
    "        Rerturn\n",
    "        -------\n",
    "        FLoat, maximum drawdown percentage\n",
    "        \"\"\"\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        watermark = mark.accumulate(net_cum_return_pct.fillna(net_cum_return_pct.min()))\n",
    "        dd = 1 - (net_cum_return_pct / watermark.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        drawdown = dd\n",
    "        return drawdown.max()\n",
    "\n",
    "\n",
    "\n",
    "    ##### 8. Gross max_DD_duration & Net max_DD_duration (Done) #####\n",
    "\n",
    "    def max_drawdown_dur(pnl, how='high'):\n",
    "        # Get Drawdown Max Duration\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        watermark = mark.accumulate(pnl.fillna(pnl.min()))\n",
    "        dd = 1 - (pnl / watermark.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        drawdown = dd\n",
    "        sr = drawdown[1:].astype(bool)\n",
    "        drawdown_dur =  sr.groupby((sr != sr.shift()).cumsum()).size()\n",
    "        return drawdown_dur.max()\n",
    "\n",
    "\n",
    "    def net_max_drawdown_dur(net_cum_return_pct, how='high'):\n",
    "        # Get Drawdown Max Duration\n",
    "        mark = np.maximum if how == 'high' else np.minimum\n",
    "        watermark = mark.accumulate(net_cum_return_pct.fillna(net_cum_return_pct.min()))\n",
    "        dd = 1 - (net_cum_return_pct / watermark.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        drawdown = dd\n",
    "        sr = drawdown[1:].astype(bool)\n",
    "        drawdown_dur =  sr.groupby((sr != sr.shift()).cumsum()).size()\n",
    "        return drawdown_dur.max()\n",
    "\n",
    "\n",
    "    ##### 9. Gross vols & Net vols (Done) #####\n",
    "\n",
    "    def annual_volatility(strategy_ret, freq_multiplier):\n",
    "        \"\"\"\n",
    "        Documentation:\n",
    "        ---------\n",
    "        Strategy_ret: Series | Numpy Array  \n",
    "        Freq_multiplier explanation: \n",
    "        Daily_Data_Freq_multiplier: 252, \n",
    "        Hourly_Data_Freq_multiplier: 252*6.5,  \n",
    "        Minutely_Data_Freq_multipler: 252*6.5*60, \n",
    "        Second_Data_Freq_multipler: 252*6.5*60*60\n",
    "        \"\"\"\n",
    "        annual_std = np.std(strategy_ret)*np.sqrt(freq_multiplier)\n",
    "        daily_std = annual_std/np.sqrt(252)\n",
    "        return annual_std\n",
    "\n",
    "    def net_annual_volatility(net_each_return_pct, freq_multiplier):\n",
    "        \"\"\"\n",
    "        Documentation:\n",
    "        ---------\n",
    "        Strategy_ret: Series | Numpy Array  \n",
    "        Freq_multiplier explanation: \n",
    "        Daily_Data_Freq_multiplier: 252, \n",
    "        Hourly_Data_Freq_multiplier: 252*6.5,  \n",
    "        Minutely_Data_Freq_multipler: 252*6.5*60, \n",
    "        Second_Data_Freq_multipler: 252*6.5*60*60\n",
    "        \"\"\"\n",
    "        annual_std = np.std(net_each_return_pct)*np.sqrt(freq_multiplier)\n",
    "        daily_std = annual_std/np.sqrt(252)\n",
    "        return annual_std\n",
    "\n",
    "\n",
    "    def daily_volatility(strategy_ret, freq_multiplier):\n",
    "        annual_std = np.std(strategy_ret)*np.sqrt(freq_multiplier)\n",
    "        daily_std = annual_std/np.sqrt(252)\n",
    "        return daily_std\n",
    "\n",
    "\n",
    "    def net_daily_volatility(net_each_return_pct, freq_multiplier):\n",
    "        annual_std = np.std(net_each_return_pct)*np.sqrt(freq_multiplier)\n",
    "        daily_std = annual_std/np.sqrt(252)\n",
    "        return daily_std\n",
    "\n",
    "\n",
    "    def vol_with_random_ts(strategy_ret):\n",
    "        return np.std(strategy_ret)\n",
    "\n",
    "\n",
    "    def net_vol_with_random_ts(net_each_return_pct):\n",
    "        return np.std(net_each_return_pct)\n",
    "\n",
    "\n",
    "    def underlying_pricing_risk_monitor(underlying_prices, window):\n",
    "        pricing_error_level = underlying_prices - underlying_prices.rolling(window).mean()\n",
    "        return pricing_error_level\n",
    "\n",
    "\n",
    "class TearSheet(object):\n",
    "\n",
    "    \"\"\"\n",
    "    The class helps return all strategy risk metrcis stats as well as stats plots\n",
    "    \"\"\"\n",
    "    def __init__(self, core_bt_df2_bm, freq_multiplier, show_all, benchmark_rdnm_str, benchmark_str, rolling_window):\n",
    "        \n",
    "        self.core_bt_df2_bm = core_bt_df2_bm\n",
    "        self.ticker_qty = core_bt_df2_bm.ticker_qty\n",
    "        self.net_each_return_pct = core_bt_df2_bm.net_each_return_pct\n",
    "        self.cum_profit = core_bt_df2_bm.cum_profit\n",
    "        self.cum_commissions = core_bt_df2_bm.cum_commissions\n",
    "        self.net_cum_profit = core_bt_df2_bm.net_cum_profit\n",
    "        self.net_cum_return_pct = core_bt_df2_bm.net_cum_return_pct\n",
    "        self.cum_trades = core_bt_df2_bm.cum_trades\n",
    "        self.volume_impact_pct = core_bt_df2_bm.volume_impact_pct\n",
    "        self.filled_price_impact_pct = core_bt_df2_bm.filled_price_impact_pct\n",
    "        self.strategy_ret = core_bt_df2_bm['each_return_pct']\n",
    "        self.freq_multiplier = freq_multiplier\n",
    "        self.pnl = core_bt_df2_bm['cum_return_pct']\n",
    "        self.benchmark_ret = core_bt_df2_bm['benchmark_ret']\n",
    "        self.benchmark_str = benchmark_str\n",
    "        self.show_all = show_all\n",
    "        self.ticker_price = core_bt_df2_bm.ticker_price\n",
    "        self.how = 'high'\n",
    "        self.rolling_window = rolling_window\n",
    "        self.cum_slippage = core_bt_df2_bm.filled_price_impact_abs.cumsum()\n",
    "        self.volume_limit = 0.025\n",
    "        self.benchmark_cum_ret = core_bt_df2_bm['benchmark_cum_ret']\n",
    "        self.benchmark_rdnm_str = benchmark_rdnm_str\n",
    "        self.rolling_window = rolling_window\n",
    "        self.commission_fees_impact_level = core_bt_df2_bm.commission_fees_impact_level\n",
    "        # Federal funds rate set as risk-free rate: https://fred.stlouisfed.org/series/FEDFUNDS\n",
    "\n",
    "\n",
    "    def print_trade_risk_metrics(self): \n",
    "               \n",
    "##### Calculate gross watermark and gross drawdown #####\n",
    "        mark = np.maximum if self.how == 'high' else np.minimum\n",
    "        # Calculating water_mark_sr\n",
    "        water_mark_sr = mark.accumulate(self.pnl.fillna(self.pnl.min()))\n",
    "        # Calculating drawdown_sr\n",
    "        dd = 1 - (self.pnl / water_mark_sr.shift(1))\n",
    "        dd.ix[dd < 0] = 0\n",
    "        drawdown_sr = dd\n",
    "\n",
    "##### Calculate net watermark and net drawdown #####\n",
    "        net_mark = np.maximum if self.how == 'high' else np.minimum\n",
    "        # Calculating water_mark_sr\n",
    "        net_water_mark_sr = mark.accumulate(self.net_cum_return_pct.fillna(self.net_cum_return_pct.min()))\n",
    "        # Calculating drawdown_sr\n",
    "        net_dd = 1 - (self.net_cum_return_pct / net_water_mark_sr.shift(1))\n",
    "        net_dd.ix[net_dd < 0] = 0\n",
    "        net_drawdown_sr = net_dd\n",
    "\n",
    "\n",
    "        fig = plt.figure(figsize = (30, 100))\n",
    "        ax1 = fig.add_subplot(15, 1, 1)\n",
    "        ax2 = fig.add_subplot(15, 1, 2)\n",
    "        ax3 = fig.add_subplot(15, 1, 3)\n",
    "        ax4 = fig.add_subplot(15, 1, 4)\n",
    "        ax5 = fig.add_subplot(15, 1, 5)\n",
    "        ax6 = fig.add_subplot(15, 1, 6)\n",
    "        ax7 = fig.add_subplot(15, 1, 7)\n",
    "        ax8 = fig.add_subplot(15, 1, 8)\n",
    "        ax9 = fig.add_subplot(15, 1, 9)\n",
    "        ax10 = fig.add_subplot(15, 1, 10)\n",
    "        ax11 = fig.add_subplot(15, 1, 11)\n",
    "        ax12 = fig.add_subplot(15, 1, 12)\n",
    "        ax13 = fig.add_subplot(15, 1, 13)\n",
    "        ax14 = fig.add_subplot(15, 1, 14)\n",
    "        ax15 = fig.add_subplot(15, 1, 15)\n",
    "\n",
    "\n",
    "##### Gross rolling std plotting & Net rolling std plotting #####\n",
    "\n",
    "        # calculate gross rolling volatility\n",
    "        rolling_std = self.strategy_ret.rolling(self.rolling_window).std()\n",
    "        annual_rolling_std = rolling_std*np.sqrt(self.freq_multiplier)\n",
    "\n",
    "        # calculate net rolling volatility\n",
    "        net_rolling_std = self.net_each_return_pct.rolling(self.rolling_window).std()\n",
    "        net_annual_rolling_std = net_rolling_std*np.sqrt(self.freq_multiplier)\n",
    "\n",
    "##### Gross rolling sharpe plotting & Net rolling sharpe plotting #####\n",
    "\n",
    "        # calculate gross rolling annual sharpe\n",
    "        rolling_er = self.strategy_ret.ewm(self.rolling_window).mean()\n",
    "        rolling_sharpe = rolling_er / rolling_std\n",
    "\n",
    "        # Calculate net rolling annual sharpe\n",
    "        net_rolling_er = self.net_each_return_pct.ewm(self.rolling_window).mean()\n",
    "        net_rolling_sharpe = net_rolling_er / net_rolling_std\n",
    "\n",
    "##### Calculate prepping for gross strategy's Alpha, not Jensen's constant #####\n",
    "        # set benchmark's constant\n",
    "        X1 = sm.add_constant(self.benchmark_ret) \n",
    "        # y is the values of returns of the strategy\n",
    "        y1 = self.strategy_ret\n",
    "\n",
    "        # creating the Ordinary Least Square model to get beta and alpha between strategy and benchmark return\n",
    "        model1 = sm.OLS(y1,X1).fit()\n",
    "        beta1 = model1.params[self.benchmark_str]\n",
    "        alpha1 = model1.params[\"const\"]\n",
    "\n",
    "        \n",
    "##### Calculate prepping for net strategy's Alpha, not Jensen's constant #####\n",
    "        # set benchmark's constant\n",
    "        X2 = sm.add_constant(self.benchmark_ret) \n",
    "        # y is the values of returns of the strategy\n",
    "        y2 = self.net_each_return_pct\n",
    "\n",
    "        # creating the Ordinary Least Square model to get beta and alpha between strategy and benchmark return\n",
    "        model2 = sm.OLS(y2,X2).fit()\n",
    "        beta2 = model2.params[self.benchmark_str]\n",
    "        alpha2 = model2.params[\"const\"]\n",
    "\n",
    "        gross_strategy_alpha = (self.pnl.values[-1]/self.pnl.values[0]-1) - (self.benchmark_cum_ret[-1]-1)*beta1\n",
    "        net_strategy_alpha = (self.net_cum_return_pct[-1]/self.net_cum_return_pct[0]-1) - (self.benchmark_cum_ret[-1]-1)*beta2\n",
    "\n",
    "\n",
    "        print (\"-\"*60)\n",
    "        print (\"Trading Metrics and Stats\")\n",
    "        print (\"-\"*30)\n",
    "\n",
    "        self.core_bt_df2_bm.cum_profit.plot(ax = ax1, color = 'green', lw=1)\n",
    "        (self.benchmark_cum_ret*self.net_cum_profit[0]).plot(ax = ax1, color = 'red', lw = 1)\n",
    "        ax1.set_ylabel('Cumulative Profits ($)', fontsize = 16)\n",
    "        ax1.set_title('Gross Backtested Equity Curve', fontsize = 16)\n",
    "        ax1.set_xlabel('none').set_visible(False)\n",
    "        print (\"Total Gross Net Liquid Asset, in $: {:0.02f}\".format(self.core_bt_df2_bm.cum_profit[-1]))\n",
    "        print (\"Total Gross Return: {:0.02f}%\".format((self.core_bt_df2_bm.cum_return_pct[-1]-1)*100))\n",
    "        print (\"Total Net Return: {:0.02f}%\".format(100*(self.net_cum_return_pct[-1]/self.net_cum_return_pct[0]-1)))\n",
    "        print (\"Total Benchmark Return: {:0.02f}%\".format(100*(self.benchmark_cum_ret[-1]-1)))\n",
    "\n",
    "        self.core_bt_df2_bm.cum_commissions.plot(ax = ax2, color = 'black', lw=1)\n",
    "        ax2.set_ylabel('Cumulative Commissions ($)', fontsize = 16)\n",
    "        ax2.set_title('Trading Commissions', fontsize = 16)\n",
    "        ax2.set_xlabel('none').set_visible(False)\n",
    "        print (\"Total Commission Fees, in $: {:0.02f}\".format(self.core_bt_df2_bm.cum_commissions[-1]))\n",
    "        print (\"Total Slippage Costs, in $: {:0.02f}\".format(self.cum_slippage[-1]))\n",
    "\n",
    "        self.core_bt_df2_bm.net_cum_profit.plot(ax = ax3, color = 'purple', lw=1)\n",
    "        (self.benchmark_cum_ret*self.net_cum_profit[0]).plot(ax = ax3, color = 'red', lw = 1)\n",
    "        ax3.set_ylabel('Net Cumulative Profits ($)', fontsize = 16)\n",
    "        ax3.set_title('Net Backtested Equity Curve', fontsize = 16)\n",
    "        ax3.set_xlabel('none').set_visible(False)\n",
    "        print (\"Total Net Liquid Asset after Trading Costs, in $: {:0.02f}\".format(self.core_bt_df2_bm.net_cum_profit[-1]))\n",
    "        print (\"Trading Costs Impact Level (Commissions + Slippage): {:0.02f}%\".format(100*(self.core_bt_df2_bm.cum_commissions[-1] + self.cum_slippage[-1])/abs(self.core_bt_df2_bm.net_cum_profit[-1]-self.core_bt_df2_bm.cum_profit[0])))\n",
    "\n",
    "        self.core_bt_df2_bm.cum_trades.plot(ax = ax4, lw=1)\n",
    "        ax4.set_ylabel('Cumulative Trades', fontsize = 16)\n",
    "        ax4.set_title('Cumulative Filled Trades', fontsize = 16)\n",
    "        ax4.set_xlabel('none').set_visible(False)\n",
    "        print (\"Total Trades: {}\".format(self.core_bt_df2_bm.cum_trades[-1])) \n",
    "\n",
    "        self.core_bt_df2_bm.volume_impact_pct.plot(ax = ax5, color = 'orange', lw=1)\n",
    "        ax5.set_ylabel('Trade Volume Impact', fontsize = 16)\n",
    "        ax5.set_title('Market Impact Per Trade', fontsize = 16)\n",
    "        ax5.set_xlabel('none').set_visible(False)\n",
    "        print (\"Average Volume Impact Per Trade: {:0.02f}%\".format(abs(self.core_bt_df2_bm.volume_impact_pct.mean()*100))) \n",
    "\n",
    "\n",
    "        self.core_bt_df2_bm.filled_price_impact_pct.plot(ax = ax6, color = 'blue', lw=1)\n",
    "        ax6.set_ylabel('Trade Slippage Impact', fontsize = 16)\n",
    "        ax6.set_title('Slippage Impact Per Trade', fontsize = 16)\n",
    "        ax6.set_xlabel('none').set_visible(False)\n",
    "        print (\"Average Slippage Impact Per Trade: {:0.04f}%\".format(self.core_bt_df2_bm.filled_price_impact_pct.mean()*100))\n",
    "\n",
    "        # plot gross drawdown\n",
    "        (-1 * drawdown_sr).plot(ax=ax7, kind='area', color='red', alpha=0.3, lw=1)\n",
    "        ax7.set_title('Gross Underwater/Drawdown Graph', fontsize = 16)\n",
    "        ax7.set_xlabel('none').set_visible(False)\n",
    "\n",
    "\n",
    "        # plot net drawdown\n",
    "        (-1 * net_drawdown_sr).plot(ax = ax8, kind = 'area', color = 'grey', lw = 1)\n",
    "        ax8.set_title('Net Underwater/Drawdown Graph', fontsize = 16)\n",
    "        ax8.set_xlabel('none').set_visible(False)\n",
    "\n",
    "\n",
    "        # plot gross watermark\n",
    "        water_mark_sr.plot(ax = ax9, color = 'green', lw = 1)\n",
    "        ax9.set_title('Gross Watermark Curve', fontsize = 16)\n",
    "        ax9.set_xlabel('none').set_visible(False)\n",
    "\n",
    "        # plot net watermark\n",
    "        net_water_mark_sr.plot(ax = ax10, color = 'magenta', lw = 1)\n",
    "        ax10.set_title('Net Watermark Curve', fontsize = 16)\n",
    "        ax10.set_xlabel('none').set_visible(False)\n",
    "\n",
    "        # plot gross annual rolling volatility\n",
    "        annual_rolling_std.plot(ax = ax11, color = 'purple', lw = 1)\n",
    "        ax11.set_title('Annual Rolling Volatility', fontsize = 16)\n",
    "        ax11.set_xlabel('none').set_visible(False)\n",
    "\n",
    "\n",
    "        # plot net annual rolling volatility\n",
    "        net_annual_rolling_std.plot(ax = ax12, color = 'orange', lw = 1)\n",
    "        ax12.set_title('Net Annual Rolling Volatility', fontsize = 16)\n",
    "        ax12.set_xlabel('none').set_visible(False)\n",
    "\n",
    "\n",
    "        self.core_bt_df2_bm.commission_fees_impact_level.plot(ax = ax13, color = 'black', lw = 1)\n",
    "        ax13.set_title('Commission Fees Impact Level Risk Monitor', fontsize = 16)\n",
    "        ax13.set_xlabel('none').set_visible(False)\n",
    "\n",
    "        self.ticker_qty.plot(ax = ax14, color = 'teal', lw = 1)\n",
    "        ax14.set_title('Position Monitor', fontsize = 16)\n",
    "        ax14.set_xlabel('none').set_visible(False)\n",
    "\n",
    "        RiskMetrics.underlying_pricing_risk_monitor(self.ticker_price, self.rolling_window).plot(ax = ax15, color = 'red', lw = 1)\n",
    "        ax15.set_title('Underlying Pricing Risk Monitor', fontsize = 16)\n",
    "        ax15.set_xlabel('none').set_visible(False)       \n",
    "\n",
    "\n",
    "        print (\"-\"*60)\n",
    "        print (\"Risk Metrics, excluding Trading Costs\")\n",
    "        print (\"-\"*30)\n",
    "        # Gross Stats\n",
    "        RiskMetrics.alpha_beta(self.strategy_ret, self.benchmark_ret, self.benchmark_str, self.show_all)\n",
    "        print (\"Gross Strategy Alpha: {:0.04f}\".format(gross_strategy_alpha))\n",
    "        print (\"Gross Sharpe Ratio: {:0.02f}\".format(RiskMetrics.annualized_sharpe_ratio(self.strategy_ret, self.freq_multiplier)))\n",
    "        print (\"Gross Sortino Ratio: {:0.02f}\".format(RiskMetrics.annualized_sortino_ratio(self.strategy_ret, self.freq_multiplier)))\n",
    "        print (\"Gross Gain Loss Ratio: {:0.02f}\".format(RiskMetrics.gain_loss_ratio(self.strategy_ret)))\n",
    "        print (\"Gross Max Drawdown: {:0.02f}%\".format(100*RiskMetrics.max_drawdown(self.pnl, self.how)))\n",
    "        print (\"Gross Max Drawdown Duration: {} time unit(s)\".format(RiskMetrics.max_drawdown_dur(self.pnl, self.how)))\n",
    "        print (\"Gross Time-Unit Volatility: {:0.02f}%\".format(100*RiskMetrics.vol_with_random_ts(self.strategy_ret)))\n",
    "        print (\"Gross Estimated Annual Volatility: {:0.02f}%\".format(RiskMetrics.annual_volatility(self.strategy_ret, self.freq_multiplier)))\n",
    "        # print (\"Gross Total Strategy Return: {:0.02f}%\".format(100*(self.pnl.values[-1]/self.pnl.values[0]-1)))\n",
    "        print (\"Gross Most Recent Time-Range Pnl: {:0.02f}%\".format(100*(self.pnl.values[-1]/self.pnl.values[-2]-1)))\n",
    "        print (\"Liquidity Risk Monitor: Average Risk Level: {:0.02f}%\".format(0))\n",
    "\n",
    "        print (\"-\"*60)\n",
    "        print (\"Net Risk Metrics, including Trading Costs\")\n",
    "        print (\"-\"*30)\n",
    "        # Net Stats\n",
    "        RiskMetrics.net_alpha_beta(self.net_each_return_pct, self.benchmark_ret, self.benchmark_str, self.show_all)\n",
    "        print (\"Net Strategy Alpha: {:0.04f}\".format(net_strategy_alpha))\n",
    "        print (\"Net Sharpe Ratio: {:0.02f}\".format(RiskMetrics.net_sharpe_ratio(self.net_each_return_pct, self.freq_multiplier)))\n",
    "        print (\"Net Sortino Ratio: {:0.02f}\".format(RiskMetrics.net_sortino_ratio(self.net_each_return_pct, self.freq_multiplier)))\n",
    "        print (\"Net Gain Loss Ratio: {:0.02f}\".format(RiskMetrics.net_gain_loss_ratio(self.net_each_return_pct)))\n",
    "        print (\"Net Max Drawdown: {:0.02f}%\".format(100*RiskMetrics.net_max_drawdown(self.net_cum_return_pct, self.how)))\n",
    "        print (\"Net Max Drawdown Duration: {} time unit(s)\".format(RiskMetrics.net_max_drawdown_dur(self.net_cum_return_pct, self.how)))\n",
    "        print (\"Net Time-Unit Volatility: {:0.02f}%\".format(100*RiskMetrics.vol_with_random_ts(self.net_each_return_pct)))\n",
    "        print (\"Net Estimated Annual Volatility: {:0.02f}%\".format(RiskMetrics.net_annual_volatility(self.net_each_return_pct, self.freq_multiplier)))\n",
    "        # print (\"Net Total Strategy Return: {:0.02f}%\".format(100*(self.net_cum_return_pct[-1]/self.net_cum_return_pct[0]-1)))\n",
    "        print (\"Net Most Recent Time-Range Pnl: {:0.02f}%\".format(100*(self.net_cum_return_pct[-1]/self.net_cum_return_pct[-2]-1)))\n",
    "        print (\"Liquidity Risk Monitor: Average Risk Level: {:0.02f}%\".format(abs(self.core_bt_df2_bm.volume_impact_pct.mean()*100)/self.volume_limit))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
